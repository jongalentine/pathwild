# PathWild ğŸŒ²

AI-powered wildlife location prediction platform

## Overview
PathWild uses machine learning to predict wildlife locations and activity patterns based on weather, terrain, and temporal data. The system helps outdoor enthusiasts, wildlife photographers, and hunters ethically optimize their planning and increase success rates.

## Current Focus
- **Species:** Rocky Mountain Elk (*Cervus canadensis nelsoni*)
- **Location:** Wyoming, USA
- **Model:** XGBoost classification (target: 70%+ accuracy)
- **Deployment:** AWS SageMaker
- **Website:** https://pathwild.ai

## Vision
Democratize wildlife prediction using AI, making expert-level insights accessible to everyone from weekend enthusiasts to professional guides.

## Future Expansion
- Mule deer, whitetail deer
- Waterfowl migration patterns
- Wildlife photography applications
- Multi-state coverage (Montana, Colorado, Idaho)

## Project Status
ğŸš§ **In Development** - MVP targeting October 2026 field validation

## Tech Stack
- **ML:** Python 3.11, PyTorch, scikit-learn, XGBoost
- **MLOps:** MLflow, SHAP
- **Geospatial:** Rasterio, GeoPandas, Shapely (for terrain, landcover, and spatial analysis)
- **Cloud:** AWS SageMaker, Lambda, API Gateway
- **Web:** Flask, Bootstrap
- **Data:** NOAA Weather API, Wyoming Game & Fish, SNOTEL, satellite imagery

## Quick Start

### Setup Environment
```bash
# Create conda environment (recommended - handles geospatial dependencies better)
conda env create -f environment.yml
conda activate pathwild

# Or install via pip (if not using conda)
pip install -r requirements.txt
```

**Note:** Geospatial packages (rasterio, geopandas) have binary dependencies (GDAL). Conda is recommended as it handles these dependencies automatically.

### Run Automated Data Pipeline

Process raw elk GPS collar data into training-ready datasets:

```bash
# Process all datasets end-to-end
python scripts/run_data_pipeline.py

# Process specific dataset
python scripts/run_data_pipeline.py --dataset north_bighorn

# Skip already-complete steps
python scripts/run_data_pipeline.py --skip-steps process_raw,generate_absence
```

**âš ï¸ Prerequisites:** Before running the pipeline, ensure all required environmental data files are present. The pipeline will automatically check prerequisites and fail fast if required files are missing. See [Environmental Data Prerequisites Guide](./docs/environmental_data_prerequisites.md) for detailed instructions.

**ğŸ“Š NDVI & Weather Data**: The pipeline now supports real NDVI (AppEEARS) and weather data (PRISM + Open-Meteo). Set `APPEEARS_USERNAME` and `APPEEARS_PASSWORD` environment variables to enable real NDVI data. See [NDVI/Weather Integration Status](./docs/ndvi_weather_integration_status.md) for details.

See [Automated Data Pipeline Documentation](./docs/automated_data_pipeline.md) for details.



## Project Structure
```
pathwild/
â”œâ”€â”€ config.yaml        # Configuration file
â”œâ”€â”€ data/              # Data files (not in Git)
â”‚   â”œâ”€â”€ raw/          # Original data
â”‚   â”œâ”€â”€ processed/    # Cleaned data
â”‚   â”œâ”€â”€ features/     # ML-ready features
â”‚   â”œâ”€â”€ dem/          # Digital elevation models
â”‚   â”œâ”€â”€ terrain/      # Slope, aspect data
â”‚   â”œâ”€â”€ landcover/    # Land cover classifications
â”‚   â”œâ”€â”€ canopy/       # Canopy cover data
â”‚   â”œâ”€â”€ hydrology/    # Water sources
â”‚   â”œâ”€â”€ infrastructure/ # Roads, trails
â”‚   â””â”€â”€ wildlife/     # Predator territories, activity
â”œâ”€â”€ docs/              # Documentation
â”œâ”€â”€ notebooks/         # Jupyter notebooks for exploration
â”œâ”€â”€ src/               # Production code
â”‚   â”œâ”€â”€ data/          # Data processing and context building
â”‚   â”‚   â””â”€â”€ processors.py  # DataContextBuilder, SNOTEL, Weather, Satellite clients
â”‚   â”œâ”€â”€ examples/      # Usage examples
â”‚   â”‚   â””â”€â”€ example_usage.py
â”‚   â”œâ”€â”€ features/      # Feature engineering
â”‚   â”œâ”€â”€ inference/     # Inference engine
â”‚   â”‚   â””â”€â”€ engine.py
â”‚   â”œâ”€â”€ models/        # Model training/prediction
â”‚   â”œâ”€â”€ scoring/       # Scoring and heuristic modules
â”‚   â”‚   â”œâ”€â”€ aggregator.py
â”‚   â”‚   â””â”€â”€ heuristics/  # Individual heuristic modules
â”‚   â”‚       â”œâ”€â”€ access.py
â”‚   â”‚       â”œâ”€â”€ elevation.py
â”‚   â”‚       â”œâ”€â”€ nutrition.py
â”‚   â”‚       â”œâ”€â”€ predation.py
â”‚   â”‚       â”œâ”€â”€ security.py
â”‚   â”‚       â”œâ”€â”€ snow.py
â”‚   â”‚       â”œâ”€â”€ vegetation.py
â”‚   â”‚       â”œâ”€â”€ water.py
â”‚   â”‚       â””â”€â”€ winterkill.py
â”‚   â””â”€â”€ deployment/    # AWS deployment
â””â”€â”€ tests/             # Unit tests
    â”œâ”€â”€ test_aggregator.py
    â”œâ”€â”€ test_data_context.py
    â”œâ”€â”€ test_heuristics.py
    â”œâ”€â”€ test_inference_engine.py
    â”œâ”€â”€ test_integration.py
    â””â”€â”€ test_validation.py
```

## Development Roadmap

### Phase 1 (Months 1-3): Wyoming Elk MVP
- [x] Environment setup
- [ ] Data collection (WGFD harvest data, NOAA weather)
- [ ] Feature engineering
- [ ] Model training (target: 70%+ accuracy)
- [ ] AWS deployment
- [ ] Web interface at pathwild.ai

### Phase 2 (Months 4-12): Validation & Refinement
- [ ] October 2026 field validation
- [ ] Model refinement based on real-world results
- [ ] Community beta testing
- [ ] Performance optimization

### Phase 3 (Year 2+): Multi-Species Expansion
- [ ] Mule deer predictions
- [ ] Waterfowl migration patterns
- [ ] Wildlife photography mode
- [ ] Mobile apps (iOS/Android)

## Contributing
This is a personal learning project, but feedback welcome! Open an issue or reach out.

## Contact
Jon Galentine  - jongalentine@gmail.com  
Project: https://github.com/jongalentine/pathwild  
Website: https://pathwild.ai

## License
MIT License (or your choice)

---

**PathWild** - Predict. Plan. Succeed.
