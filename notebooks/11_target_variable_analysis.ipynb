{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11: Target Variable Analysis\n",
    "\n",
    "## Purpose\n",
    "Deep dive into the target variable (presence/absence) and class balance to inform modeling decisions.\n",
    "\n",
    "## Key Questions\n",
    "- What is the target variable and how is it encoded?\n",
    "- Is there class imbalance that requires special handling?\n",
    "- Are there temporal or spatial patterns in presence?\n",
    "- Which features show strongest separation between presence/absence?\n",
    "- What baseline performance should we expect?\n",
    "\n",
    "## Key Observations to Look For\n",
    "- **Class Balance**: Imbalance >80/20 requires resampling\n",
    "- **Temporal Patterns**: Presence rate by month/year\n",
    "- **Spatial Patterns**: Hotspots and cold spots\n",
    "- **Feature Separation**: Features with clear presence/absence differences\n",
    "- **Baseline Performance**: Minimum bar for ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Determine project root and output directories\n",
    "possible_roots = [\n",
    "    Path('.'),  # If running from project root\n",
    "    Path('..'),  # If running from notebooks directory\n",
    "    Path('../..'),  # If running from subdirectory\n",
    "]\n",
    "\n",
    "data_root = None\n",
    "for root in possible_roots:\n",
    "    if (root / 'data' / 'features').exists():\n",
    "        data_root = root / 'data'\n",
    "        break\n",
    "\n",
    "if data_root is None:\n",
    "    data_root = Path('../data')\n",
    "\n",
    "# Create output directories relative to project root\n",
    "figures_dir = data_root / 'figures'\n",
    "reports_dir = data_root / 'reports'\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'✓ Setup complete')\n",
    "print(f'  Output directory: {data_root.absolute()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify Target Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from pathlib import Path\n",
    "\n",
    "# Try multiple possible paths\n",
    "possible_paths = [\n",
    "    Path('data/features/complete_context.csv'),  # From project root\n",
    "    Path('../data/features/complete_context.csv'),  # From notebooks directory\n",
    "    Path('../../data/features/complete_context.csv'),  # From subdirectory\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        data_path = path\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f'Data file not found. Tried: {[str(p) for p in possible_paths]}\\n'\n",
    "        f'Please run: python scripts/combine_feature_files.py\\n'\n",
    "        f'Or ensure you are running the notebook from the project root directory.'\n",
    "    )\n",
    "\n",
    "print(f'Loading data from: {data_path}')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Automatically detect target column\n",
    "target_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in ['presence', 'target', 'label', 'is_presence', 'elk_present']:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col:\n",
    "    print(f'Found target column: {target_col}')\n",
    "    print(f'\\nUnique values: {df[target_col].unique()}')\n",
    "    print(f'\\nValue counts:')\n",
    "    print(df[target_col].value_counts().sort_index())\n",
    "    print(f'\\nValue counts (normalized):')\n",
    "    print(df[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "    \n",
    "    # Check if binary\n",
    "    unique_vals = sorted(df[target_col].dropna().unique())\n",
    "    if len(unique_vals) == 2:\n",
    "        print(f'\\n✓ Binary classification target detected')\n",
    "        print(f'  Classes: {unique_vals}')\n",
    "    else:\n",
    "        print(f'\\n⚠ Target has {len(unique_vals)} unique values (not binary)')\n",
    "else:\n",
    "    print('⚠ No target column detected. Looking for binary columns...')\n",
    "    # Look for binary columns\n",
    "    binary_cols = []\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, True, False, '0', '1'}):\n",
    "            binary_cols.append(col)\n",
    "    \n",
    "    if len(binary_cols) > 0:\n",
    "        print(f'Found potential binary columns: {binary_cols}')\n",
    "        target_col = binary_cols[0]\n",
    "        print(f'Using: {target_col}')\n",
    "    else:\n",
    "        print('⚠ No clear target variable found. This notebook focuses on binary classification.')\n",
    "        target_col = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Balance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class balance\n",
    "if target_col:\n",
    "    class_counts = df[target_col].value_counts().sort_index()\n",
    "    class_pcts = df[target_col].value_counts(normalize=True).sort_index() * 100\n",
    "    \n",
    "    print('Class balance:')\n",
    "    for val, count in class_counts.items():\n",
    "        pct = class_pcts[val]\n",
    "        print(f'  Class {val}: {count:,} ({pct:.1f}%)')\n",
    "    \n",
    "    # Check for imbalance\n",
    "    min_pct = class_pcts.min()\n",
    "    max_pct = class_pcts.max()\n",
    "    imbalance_ratio = max_pct / min_pct if min_pct > 0 else np.inf\n",
    "    \n",
    "    print(f'\\nImbalance ratio: {imbalance_ratio:.2f}:1')\n",
    "    \n",
    "    if imbalance_ratio > 4:  # 80/20 split\n",
    "        print(f'⚠ CRITICAL: Severe class imbalance detected ({imbalance_ratio:.1f}:1)')\n",
    "        print('  Recommendation: Use resampling (SMOTE, undersampling) or class weights')\n",
    "    elif imbalance_ratio > 2:  # 67/33 split\n",
    "        print(f'⚠ WARNING: Moderate class imbalance ({imbalance_ratio:.1f}:1)')\n",
    "        print('  Recommendation: Consider class weights in model training')\n",
    "    else:\n",
    "        print(f'✓ Classes are relatively balanced ({imbalance_ratio:.1f}:1)')\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[0].pie(class_counts.values, labels=[f'Class {x}' for x in class_counts.index],\n",
    "                autopct='%1.1f%%', startangle=90, colors=['steelblue', 'coral'])\n",
    "    axes[0].set_title('Class Distribution (Pie Chart)', fontsize=14)\n",
    "    \n",
    "    # Bar chart\n",
    "    axes[1].bar(range(len(class_counts)), class_counts.values, \n",
    "                color=['steelblue', 'coral'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xticks(range(len(class_counts)))\n",
    "    axes[1].set_xticklabels([f'Class {x}' for x in class_counts.index])\n",
    "    axes[1].set_ylabel('Count', fontsize=12)\n",
    "    axes[1].set_title('Class Distribution (Bar Chart)', fontsize=14)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (val, count) in enumerate(class_counts.items()):\n",
    "        axes[1].text(i, count, f'{count:,}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'class_balance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✓ Saved class balance visualizations')\n",
    "else:\n",
    "    print('⚠ Cannot analyze class balance without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Presence Patterns by Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns in presence\n",
    "if target_col:\n",
    "    # Check for month column\n",
    "    month_col = None\n",
    "    if 'month' in df.columns:\n",
    "        month_col = 'month'\n",
    "    \n",
    "    if month_col:\n",
    "        # Presence rate by month\n",
    "        monthly_presence = df.groupby(month_col).agg({\n",
    "            target_col: ['sum', 'count', 'mean']\n",
    "        })\n",
    "        monthly_presence.columns = ['presences', 'total', 'presence_rate']\n",
    "        monthly_presence['presence_rate_pct'] = monthly_presence['presence_rate'] * 100\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(monthly_presence.index, monthly_presence['presence_rate_pct'], \n",
    "                marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "        plt.axhline(50, color='red', linestyle='--', linewidth=1, alpha=0.5, label='50% baseline')\n",
    "        plt.xlabel('Month', fontsize=12)\n",
    "        plt.ylabel('Presence Rate (%)', fontsize=12)\n",
    "        plt.title('Presence Rate by Month', fontsize=14, pad=20)\n",
    "        plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "        plt.ylim(0, 105)\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / 'presence_temporal_pattern.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\nPresence rate by month:')\n",
    "        print(monthly_presence[['presences', 'total', 'presence_rate_pct']])\n",
    "        \n",
    "        # Check for year column\n",
    "        if 'year' in df.columns:\n",
    "            yearly_presence = df.groupby('year').agg({\n",
    "                target_col: ['sum', 'count', 'mean']\n",
    "            })\n",
    "            yearly_presence.columns = ['presences', 'total', 'presence_rate']\n",
    "            yearly_presence['presence_rate_pct'] = yearly_presence['presence_rate'] * 100\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(yearly_presence.index, yearly_presence['presence_rate_pct'], \n",
    "                    marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "            plt.xlabel('Year', fontsize=12)\n",
    "            plt.ylabel('Presence Rate (%)', fontsize=12)\n",
    "            plt.title('Presence Rate by Year', fontsize=14, pad=20)\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(figures_dir / 'presence_yearly_pattern.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print('\\nPresence rate by year:')\n",
    "            print(yearly_presence[['presences', 'total', 'presence_rate_pct']])\n",
    "        \n",
    "        print('\\n### Key Observations:')\n",
    "        peak_month = monthly_presence['presence_rate_pct'].idxmax()\n",
    "        low_month = monthly_presence['presence_rate_pct'].idxmin()\n",
    "        print(f'  - Highest presence rate: Month {peak_month} ({monthly_presence.loc[peak_month, \"presence_rate_pct\"]:.1f}%)')\n",
    "        print(f'  - Lowest presence rate: Month {low_month} ({monthly_presence.loc[low_month, \"presence_rate_pct\"]:.1f}%)')\n",
    "        \n",
    "        if peak_month in [9, 10, 11]:  # Sep, Oct, Nov\n",
    "            print('  - Peak in fall months may indicate hunting season bias')\n",
    "        \n",
    "        print('\\n✓ Saved temporal pattern visualizations')\n",
    "    else:\n",
    "        print('⚠ Cannot analyze temporal patterns without month column')\n",
    "else:\n",
    "    print('⚠ Cannot analyze temporal patterns without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Presence Patterns by Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial patterns in presence\n",
    "if target_col:\n",
    "    # Detect lat/lon columns\n",
    "    lat_col = None\n",
    "    lon_col = None\n",
    "    for col in df.columns:\n",
    "        if 'lat' in col.lower() and 'lon' not in col.lower():\n",
    "            lat_col = col\n",
    "        if 'lon' in col.lower() and 'lat' not in col.lower():\n",
    "            lon_col = col\n",
    "    \n",
    "    if lat_col and lon_col:\n",
    "        # Create hexbin map of presence rate\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Sample if too many points\n",
    "        sample_size = min(50000, len(df))\n",
    "        df_sample = df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # Create hexbin plot colored by presence rate\n",
    "        hb = plt.hexbin(df_sample[lon_col], df_sample[lat_col], \n",
    "                       C=df_sample[target_col], gridsize=30, cmap='RdYlGn',\n",
    "                       reduce_C_function=np.mean, mincnt=10)\n",
    "        \n",
    "        plt.colorbar(hb, label='Presence Rate')\n",
    "        plt.xlabel('Longitude', fontsize=12)\n",
    "        plt.ylabel('Latitude', fontsize=12)\n",
    "        plt.title(f'Presence Rate Spatial Heatmap (n={sample_size:,} points)', fontsize=14, pad=20)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / 'presence_spatial_pattern.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print('✓ Saved spatial presence pattern')\n",
    "        \n",
    "        # Calculate presence rate by region (rough grid)\n",
    "        df['lat_bin'] = pd.cut(df[lat_col], bins=10, labels=False)\n",
    "        df['lon_bin'] = pd.cut(df[lon_col], bins=10, labels=False)\n",
    "        regional_presence = df.groupby(['lat_bin', 'lon_bin'])[target_col].agg(['mean', 'count'])\n",
    "        regional_presence.columns = ['presence_rate', 'count']\n",
    "        \n",
    "        print('\\n### Key Observations:')\n",
    "        high_regions = regional_presence[regional_presence['presence_rate'] > 0.6]\n",
    "        low_regions = regional_presence[regional_presence['presence_rate'] < 0.4]\n",
    "        print(f'  - High-presence regions (>60%): {len(high_regions)}')\n",
    "        print(f'  - Low-presence regions (<40%): {len(low_regions)}')\n",
    "        print(f'  - Spatial coverage: {df[[lat_col, lon_col]].drop_duplicates().shape[0]:,} unique locations')\n",
    "    else:\n",
    "        print('⚠ Cannot analyze spatial patterns without lat/lon columns')\n",
    "else:\n",
    "    print('⚠ Cannot analyze spatial patterns without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Distributions: Presence vs Absence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plots comparing presence vs absence for each feature\n",
    "if target_col:\n",
    "    # Get numeric columns (exclude target and index columns)\n",
    "    numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                   if col not in [target_col, 'point_index', 'lat_bin', 'lon_bin']]\n",
    "    \n",
    "    # Select top 12 features by variance\n",
    "    feature_variance = df[numeric_cols].var().sort_values(ascending=False)\n",
    "    top_features = feature_variance.head(12).index.tolist()\n",
    "    \n",
    "    n_cols = 3\n",
    "    n_rows = (len(top_features) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for idx, col in enumerate(top_features):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        presence_data = df[df[target_col] == 1][col].dropna()\n",
    "        absence_data = df[df[target_col] == 0][col].dropna()\n",
    "        \n",
    "        if len(presence_data) > 0 and len(absence_data) > 0:\n",
    "            # Violin plots\n",
    "            data_to_plot = [presence_data, absence_data]\n",
    "            parts = ax.violinplot(data_to_plot, positions=[0, 1], showmeans=True, showmedians=True)\n",
    "            \n",
    "            # Color violins\n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor('steelblue')\n",
    "                pc.set_alpha(0.7)\n",
    "            \n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_xticklabels(['Presence', 'Absence'])\n",
    "            ax.set_ylabel(col, fontsize=10)\n",
    "            ax.set_title(col, fontsize=11)\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Statistical test\n",
    "            t_stat, p_value = ttest_ind(presence_data, absence_data)\n",
    "            mean_diff = presence_data.mean() - absence_data.mean()\n",
    "            \n",
    "            # Effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt((presence_data.std()**2 + absence_data.std()**2) / 2)\n",
    "            cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            test_results.append({\n",
    "                'feature': col,\n",
    "                'p_value': p_value,\n",
    "                'cohens_d': cohens_d,\n",
    "                'mean_diff': mean_diff,\n",
    "                'significant': p_value < 0.01\n",
    "            })\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(len(top_features), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Feature Distributions: Presence vs Absence (Violin Plots)', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'presence_feature_violins.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('✓ Saved violin plots')\n",
    "    \n",
    "    # Print statistical test results\n",
    "    if len(test_results) > 0:\n",
    "        results_df = pd.DataFrame(test_results).sort_values('p_value')\n",
    "        print('\\n### Statistical Test Results (sorted by p-value):')\n",
    "        print(results_df)\n",
    "        \n",
    "        significant = results_df[results_df['significant']]\n",
    "        print(f'\\n✓ {len(significant)} features show significant difference (p<0.01):')\n",
    "        for _, row in significant.head(10).iterrows():\n",
    "            print(f\"  - {row['feature']}: p={row['p_value']:.2e}, Cohen's d={row['cohens_d']:.2f}\")\n",
    "else:\n",
    "    print('⚠ Cannot compare feature distributions without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Presence Prediction Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple baseline models\n",
    "if target_col:\n",
    "    y_true = df[target_col].dropna()\n",
    "    \n",
    "    # Baseline 1: Random guess (50/50)\n",
    "    np.random.seed(42)\n",
    "    y_random = np.random.randint(0, 2, size=len(y_true))\n",
    "    acc_random = accuracy_score(y_true, y_random)\n",
    "    \n",
    "    # Baseline 2: Always predict majority class\n",
    "    majority_class = y_true.mode()[0]\n",
    "    y_majority = np.full(len(y_true), majority_class)\n",
    "    acc_majority = accuracy_score(y_true, y_majority)\n",
    "    \n",
    "    # Baseline 3: Best single feature (if we have test results)\n",
    "    best_feature_acc = 0\n",
    "    best_feature_name = None\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        # Use feature with highest |Cohen's d|\n",
    "        best_feature = results_df.loc[results_df['cohens_d'].abs().idxmax(), 'feature']\n",
    "        best_feature_name = best_feature\n",
    "        \n",
    "        # Create threshold-based classifier\n",
    "        presence_data = df[df[target_col] == 1][best_feature].dropna()\n",
    "        absence_data = df[df[target_col] == 0][best_feature].dropna()\n",
    "        \n",
    "        if len(presence_data) > 0 and len(absence_data) > 0:\n",
    "            threshold = (presence_data.median() + absence_data.median()) / 2\n",
    "            valid_mask = df[best_feature].notna() & df[target_col].notna()\n",
    "            y_feature = (df.loc[valid_mask, best_feature] > threshold).astype(int)\n",
    "            y_true_feature = df.loc[valid_mask, target_col]\n",
    "            \n",
    "            if len(y_feature) > 0:\n",
    "                best_feature_acc = accuracy_score(y_true_feature, y_feature)\n",
    "                prec_feature = precision_score(y_true_feature, y_feature, zero_division=0)\n",
    "                rec_feature = recall_score(y_true_feature, y_feature, zero_division=0)\n",
    "                f1_feature = f1_score(y_true_feature, y_feature, zero_division=0)\n",
    "    \n",
    "    # Print baseline results\n",
    "    print('### Baseline Model Performance:')\n",
    "    print(f'\\n1. Random Guess (50/50):')\n",
    "    print(f'   Accuracy: {acc_random:.3f}')\n",
    "    \n",
    "    print(f'\\n2. Always Predict Majority Class ({majority_class}):')\n",
    "    print(f'   Accuracy: {acc_majority:.3f}')\n",
    "    \n",
    "    if best_feature_name:\n",
    "        print(f'\\n3. Single Best Feature ({best_feature_name}):')\n",
    "        print(f'   Accuracy: {best_feature_acc:.3f}')\n",
    "        print(f'   Precision: {prec_feature:.3f}')\n",
    "        print(f'   Recall: {rec_feature:.3f}')\n",
    "        print(f'   F1-Score: {f1_feature:.3f}')\n",
    "    \n",
    "    # Create comparison bar chart\n",
    "    baseline_names = ['Random', 'Majority', 'Best Feature']\n",
    "    baseline_accs = [acc_random, acc_majority, best_feature_acc if best_feature_name else 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['red' if x < 0.6 else 'orange' if x < 0.7 else 'green' for x in baseline_accs]\n",
    "    bars = plt.bar(baseline_names, baseline_accs, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.axhline(0.7, color='green', linestyle='--', linewidth=2, label='Target (70%)')\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Baseline Model Performance Comparison', fontsize=14, pad=20)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, baseline_accs):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'baseline_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✓ Saved baseline performance comparison')\n",
    "    print(f'\\n### Recommendation:')\n",
    "    best_baseline = max(baseline_accs)\n",
    "    print(f'  ML models must achieve >{best_baseline:.3f} accuracy to be useful')\n",
    "    print(f'  Target accuracy: 70%+ (as specified in project goals)')\n",
    "else:\n",
    "    print('⚠ Cannot create baselines without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive modeling recommendations\n",
    "if target_col:\n",
    "    recommendations = []\n",
    "    \n",
    "    # Class imbalance recommendations\n",
    "    if 'imbalance_ratio' in locals():\n",
    "        if imbalance_ratio > 4:\n",
    "            recommendations.append({\n",
    "                'category': 'Class Imbalance',\n",
    "                'issue': f'Severe imbalance ({imbalance_ratio:.1f}:1)',\n",
    "                'recommendation': 'Use SMOTE oversampling or class weights in model',\n",
    "                'priority': 'HIGH'\n",
    "            })\n",
    "        elif imbalance_ratio > 2:\n",
    "            recommendations.append({\n",
    "                'category': 'Class Imbalance',\n",
    "                'issue': f'Moderate imbalance ({imbalance_ratio:.1f}:1)',\n",
    "                'recommendation': 'Consider class weights in model training',\n",
    "                'priority': 'MEDIUM'\n",
    "            })\n",
    "    \n",
    "    # Train/test split recommendations\n",
    "    if 'month_col' in locals() and month_col:\n",
    "        recommendations.append({\n",
    "            'category': 'Train/Test Split',\n",
    "            'issue': 'Temporal data with seasonal patterns',\n",
    "            'recommendation': 'Use temporal split (train on earlier years, test on later) or stratified by month',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'category': 'Train/Test Split',\n",
    "            'issue': 'No clear temporal structure',\n",
    "            'recommendation': 'Use stratified random split to maintain class balance',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "    \n",
    "    # Evaluation metrics recommendations\n",
    "    if 'imbalance_ratio' in locals() and imbalance_ratio > 2:\n",
    "        recommendations.append({\n",
    "            'category': 'Evaluation Metrics',\n",
    "            'issue': 'Class imbalance makes accuracy misleading',\n",
    "            'recommendation': 'Focus on F1-score, precision, recall, and AUC-ROC instead of accuracy',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'category': 'Evaluation Metrics',\n",
    "            'issue': 'Relatively balanced classes',\n",
    "            'recommendation': 'Accuracy is acceptable, but also track F1-score and AUC-ROC',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "    \n",
    "    # Baseline performance\n",
    "    if 'best_baseline' in locals():\n",
    "        recommendations.append({\n",
    "            'category': 'Baseline Performance',\n",
    "            'issue': f'Best baseline achieves {best_baseline:.3f} accuracy',\n",
    "            'recommendation': f'ML models must exceed {best_baseline:.3f} to be useful. Target: 70%+',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    \n",
    "    # Save recommendations\n",
    "    if len(recommendations) > 0:\n",
    "        rec_df = pd.DataFrame(recommendations)\n",
    "        \n",
    "        print('### Modeling Recommendations:')\n",
    "        print(rec_df.to_string(index=False))\n",
    "        \n",
    "        report = f'''# Modeling Recommendations for PathWild\n",
    "\n",
    "Generated: {pd.Timestamp.now()}\n",
    "\n",
    "## Summary\n",
    "\n",
    "Based on target variable analysis, the following recommendations are provided for model development.\n",
    "\n",
    "## Recommendations by Category\n",
    "\n",
    "'''\n",
    "        \n",
    "        for category in rec_df['category'].unique():\n",
    "            category_recs = rec_df[rec_df['category'] == category]\n",
    "            report += f'\\n### {category}\\n\\n'\n",
    "            for _, rec in category_recs.iterrows():\n",
    "                report += f'- **Priority**: {rec[\"priority\"]}\\n'\n",
    "                report += f'  - **Issue**: {rec[\"issue\"]}\\n'\n",
    "                report += f'  - **Recommendation**: {rec[\"recommendation\"]}\\n\\n'\n",
    "        \n",
    "        report += '''\n",
    "## Next Steps\n",
    "\n",
    "1. Address high-priority recommendations before model training\n",
    "2. Set up appropriate train/test split strategy\n",
    "3. Choose evaluation metrics based on class balance\n",
    "4. Establish baseline performance targets\n",
    "5. Proceed with feature engineering and model selection\n",
    "\n",
    "## Target Performance\n",
    "\n",
    "- **Minimum**: Exceed best baseline performance\n",
    "- **Target**: 70%+ accuracy (as specified in project goals)\n",
    "- **Metrics**: Track accuracy, F1-score, precision, recall, and AUC-ROC\n",
    "'''\n",
    "        \n",
    "        with open(reports_dir / 'modeling_recommendations.md', 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print('\\n✓ Saved recommendations to data/reports/modeling_recommendations.md')\n",
    "    else:\n",
    "        print('⚠ Could not generate recommendations')\n",
    "else:\n",
    "    print('⚠ Cannot generate recommendations without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
