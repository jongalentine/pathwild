{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11: Target Variable Analysis\n",
    "\n",
    "## Purpose\n",
    "Deep dive into the target variable (presence/absence) and class balance to inform modeling decisions.\n",
    "\n",
    "## Key Questions\n",
    "- What is the target variable and how is it encoded?\n",
    "- Is there class imbalance that requires special handling?\n",
    "- Are there temporal or spatial patterns in presence?\n",
    "- Which features show strongest separation between presence/absence?\n",
    "- What baseline performance should we expect?\n",
    "\n",
    "## Key Observations to Look For\n",
    "- **Class Balance**: Imbalance >80/20 requires resampling\n",
    "- **Temporal Patterns**: Presence rate by month/year\n",
    "- **Spatial Patterns**: Hotspots and cold spots\n",
    "- **Feature Separation**: Features with clear presence/absence differences\n",
    "- **Baseline Performance**: Minimum bar for ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Determine project root and output directories\n",
    "possible_roots = [\n",
    "    Path('.'),  # If running from project root\n",
    "    Path('..'),  # If running from notebooks directory\n",
    "    Path('../..'),  # If running from subdirectory\n",
    "]\n",
    "\n",
    "data_root = None\n",
    "for root in possible_roots:\n",
    "    if (root / 'data' / 'features').exists():\n",
    "        data_root = root / 'data'\n",
    "        break\n",
    "\n",
    "if data_root is None:\n",
    "    data_root = Path('../data')\n",
    "\n",
    "# Create output directories relative to project root\n",
    "figures_dir = data_root / 'figures'\n",
    "reports_dir = data_root / 'reports'\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'✓ Setup complete')\n",
    "print(f'  Output directory: {data_root.absolute()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify Target Variable\n",
    "\n",
    "The target variable (presence/absence) is the outcome we're trying to predict. This section identifies the target column and examines its encoding and distribution.\n",
    "\n",
    "### What to Look For\n",
    "- Confirm target column is detected (elk_present, presence, or similar)\n",
    "- Verify binary encoding (0/1 or True/False)\n",
    "- Note total sample size for power considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from pathlib import Path\n",
    "\n",
    "# Try multiple possible paths\n",
    "possible_paths = [\n",
    "    Path('data/features/complete_context.csv'),  # From project root\n",
    "    Path('../data/features/complete_context.csv'),  # From notebooks directory\n",
    "    Path('../../data/features/complete_context.csv'),  # From subdirectory\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        data_path = path\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f'Data file not found. Tried: {[str(p) for p in possible_paths]}\\n'\n",
    "        f'Please run: python scripts/combine_feature_files.py\\n'\n",
    "        f'Or ensure you are running the notebook from the project root directory.'\n",
    "    )\n",
    "\n",
    "print(f'Loading data from: {data_path}')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Automatically detect target column\n",
    "target_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in ['presence', 'target', 'label', 'is_presence', 'elk_present']:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col:\n",
    "    print(f'Found target column: {target_col}')\n",
    "    print(f'\\nUnique values: {df[target_col].unique()}')\n",
    "    print(f'\\nValue counts:')\n",
    "    print(df[target_col].value_counts().sort_index())\n",
    "    print(f'\\nValue counts (normalized):')\n",
    "    print(df[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "    \n",
    "    # Check if binary\n",
    "    unique_vals = sorted(df[target_col].dropna().unique())\n",
    "    if len(unique_vals) == 2:\n",
    "        print(f'\\n✓ Binary classification target detected')\n",
    "        print(f'  Classes: {unique_vals}')\n",
    "    else:\n",
    "        print(f'\\n⚠ Target has {len(unique_vals)} unique values (not binary)')\n",
    "else:\n",
    "    print('⚠ No target column detected. Looking for binary columns...')\n",
    "    # Look for binary columns\n",
    "    binary_cols = []\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, True, False, '0', '1'}):\n",
    "            binary_cols.append(col)\n",
    "    \n",
    "    if len(binary_cols) > 0:\n",
    "        print(f'Found potential binary columns: {binary_cols}')\n",
    "        target_col = binary_cols[0]\n",
    "        print(f'Using: {target_col}')\n",
    "    else:\n",
    "        print('⚠ No clear target variable found. This notebook focuses on binary classification.')\n",
    "        target_col = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Balance Analysis\n",
    "\n",
    "Class imbalance is one of the most important considerations for binary classification. This section quantifies the balance between presence and absence observations and determines if special handling is needed.\n",
    "\n",
    "### What This Code Does\n",
    "- Counts presence and absence observations\n",
    "- Calculates class percentages and imbalance ratio\n",
    "- Creates pie and bar chart visualizations\n",
    "- Provides recommendations based on imbalance severity\n",
    "\n",
    "### Understanding Class Imbalance\n",
    "\n",
    "**Imbalance Ratio:**\n",
    "The ratio of majority to minority class (e.g., 2:1 means twice as many of one class)\n",
    "\n",
    "**Imbalance Thresholds:**\n",
    "- **< 2:1**: Balanced - no special handling needed\n",
    "- **2:1 to 4:1**: Moderate - consider class weights\n",
    "- **4:1 to 10:1**: Severe - use resampling or specialized algorithms\n",
    "- **> 10:1**: Extreme - may need anomaly detection approach\n",
    "\n",
    "### What to Look For\n",
    "- **~50/50 split**: Ideal for standard ML algorithms\n",
    "- **60/40 to 70/30**: Still workable with class weights\n",
    "- **>80/20**: Accuracy becomes misleading metric\n",
    "- **Pseudo-absence ratio**: Should match study design (often 1:1 or 1:2)\n",
    "\n",
    "### Implications for Modeling\n",
    "\n",
    "**If Imbalanced:**\n",
    "1. **Use F1-score** instead of accuracy as primary metric\n",
    "2. **Apply class weights** in model training\n",
    "3. **Consider SMOTE** oversampling of minority class\n",
    "4. **Use stratified** train/test split to maintain ratio\n",
    "\n",
    "**Elk Ecology Context:**\n",
    "In habitat studies, 1:1 presence:absence ratio is common by design (one pseudo-absence per presence). Higher absence ratios (1:2 or 1:3) are sometimes used to better characterize \"available\" habitat. The ratio reflects study design choices, not natural occurrence rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class balance\n",
    "if target_col:\n",
    "    class_counts = df[target_col].value_counts().sort_index()\n",
    "    class_pcts = df[target_col].value_counts(normalize=True).sort_index() * 100\n",
    "    \n",
    "    print('Class balance:')\n",
    "    for val, count in class_counts.items():\n",
    "        pct = class_pcts[val]\n",
    "        print(f'  Class {val}: {count:,} ({pct:.1f}%)')\n",
    "    \n",
    "    # Check for imbalance\n",
    "    min_pct = class_pcts.min()\n",
    "    max_pct = class_pcts.max()\n",
    "    imbalance_ratio = max_pct / min_pct if min_pct > 0 else np.inf\n",
    "    \n",
    "    print(f'\\nImbalance ratio: {imbalance_ratio:.2f}:1')\n",
    "    \n",
    "    if imbalance_ratio > 4:  # 80/20 split\n",
    "        print(f'⚠ CRITICAL: Severe class imbalance detected ({imbalance_ratio:.1f}:1)')\n",
    "        print('  Recommendation: Use resampling (SMOTE, undersampling) or class weights')\n",
    "    elif imbalance_ratio > 2:  # 67/33 split\n",
    "        print(f'⚠ WARNING: Moderate class imbalance ({imbalance_ratio:.1f}:1)')\n",
    "        print('  Recommendation: Consider class weights in model training')\n",
    "    else:\n",
    "        print(f'✓ Classes are relatively balanced ({imbalance_ratio:.1f}:1)')\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[0].pie(class_counts.values, labels=[f'Class {x}' for x in class_counts.index],\n",
    "                autopct='%1.1f%%', startangle=90, colors=['steelblue', 'coral'])\n",
    "    axes[0].set_title('Class Distribution (Pie Chart)', fontsize=14)\n",
    "    \n",
    "    # Bar chart\n",
    "    axes[1].bar(range(len(class_counts)), class_counts.values, \n",
    "                color=['steelblue', 'coral'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xticks(range(len(class_counts)))\n",
    "    axes[1].set_xticklabels([f'Class {x}' for x in class_counts.index])\n",
    "    axes[1].set_ylabel('Count', fontsize=12)\n",
    "    axes[1].set_title('Class Distribution (Bar Chart)', fontsize=14)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (val, count) in enumerate(class_counts.items()):\n",
    "        axes[1].text(i, count, f'{count:,}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'class_balance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✓ Saved class balance visualizations')\n",
    "else:\n",
    "    print('⚠ Cannot analyze class balance without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Presence Patterns by Time\n",
    "\n",
    "Temporal patterns in presence rate may indicate data collection biases or real ecological patterns. This section analyzes how presence rate varies by month and year.\n",
    "\n",
    "### What This Code Does\n",
    "- Calculates presence rate (% presence) for each month\n",
    "- Calculates presence rate for each year\n",
    "- Creates line plots showing temporal trends\n",
    "\n",
    "### Interpreting Temporal Presence Patterns\n",
    "\n",
    "**Expected Pattern (for balanced pseudo-absences):**\n",
    "- Presence rate should be roughly constant (~50%) across months\n",
    "- If pseudo-absences are matched to presence months, this is expected\n",
    "\n",
    "**Concerning Patterns:**\n",
    "- **Monthly variation >10%**: May indicate seasonal data collection bias\n",
    "- **Year-over-year trend**: May indicate population change or changing study effort\n",
    "- **Single month spike**: May indicate data entry error or special collection event\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "**Monthly Pattern:**\n",
    "- **Constant ~50%**: Good - balanced sampling across seasons\n",
    "- **Summer peak**: More presence data collected in summer (access?)\n",
    "- **Winter peak**: More presence data collected in winter (concentration areas?)\n",
    "- **Hunting season dip (Sep-Nov)**: Possible elk behavior change affecting collar data\n",
    "\n",
    "**Yearly Pattern:**\n",
    "- **Stable across years**: Good temporal generalization expected\n",
    "- **Increasing trend**: Growing dataset or population\n",
    "- **Decreasing trend**: Declining coverage or population\n",
    "- **Missing years**: Gaps in data collection\n",
    "\n",
    "### Elk Ecology Context\n",
    "Seasonal variation in presence rate is NOT the same as seasonal variation in elk presence probability. The rate here reflects data collection, not ecology. However:\n",
    "- Higher presence rates when elk are concentrated (winter) may be expected\n",
    "- Lower presence rates when elk are dispersed (summer) may be expected\n",
    "- True seasonal behavior is captured in environmental features, not presence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns in presence\n",
    "if target_col:\n",
    "    # Check for month column\n",
    "    month_col = None\n",
    "    if 'month' in df.columns:\n",
    "        month_col = 'month'\n",
    "    \n",
    "    if month_col:\n",
    "        # Presence rate by month\n",
    "        monthly_presence = df.groupby(month_col).agg({\n",
    "            target_col: ['sum', 'count', 'mean']\n",
    "        })\n",
    "        monthly_presence.columns = ['presences', 'total', 'presence_rate']\n",
    "        monthly_presence['presence_rate_pct'] = monthly_presence['presence_rate'] * 100\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(monthly_presence.index, monthly_presence['presence_rate_pct'], \n",
    "                marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "        plt.axhline(50, color='red', linestyle='--', linewidth=1, alpha=0.5, label='50% baseline')\n",
    "        plt.xlabel('Month', fontsize=12)\n",
    "        plt.ylabel('Presence Rate (%)', fontsize=12)\n",
    "        plt.title('Presence Rate by Month', fontsize=14, pad=20)\n",
    "        plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "        plt.ylim(0, 105)\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / 'presence_temporal_pattern.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\nPresence rate by month:')\n",
    "        print(monthly_presence[['presences', 'total', 'presence_rate_pct']])\n",
    "        \n",
    "        # Check for year column\n",
    "        if 'year' in df.columns:\n",
    "            yearly_presence = df.groupby('year').agg({\n",
    "                target_col: ['sum', 'count', 'mean']\n",
    "            })\n",
    "            yearly_presence.columns = ['presences', 'total', 'presence_rate']\n",
    "            yearly_presence['presence_rate_pct'] = yearly_presence['presence_rate'] * 100\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(yearly_presence.index, yearly_presence['presence_rate_pct'], \n",
    "                    marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "            plt.xlabel('Year', fontsize=12)\n",
    "            plt.ylabel('Presence Rate (%)', fontsize=12)\n",
    "            plt.title('Presence Rate by Year', fontsize=14, pad=20)\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(figures_dir / 'presence_yearly_pattern.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print('\\nPresence rate by year:')\n",
    "            print(yearly_presence[['presences', 'total', 'presence_rate_pct']])\n",
    "        \n",
    "        print('\\n### Key Observations:')\n",
    "        peak_month = monthly_presence['presence_rate_pct'].idxmax()\n",
    "        low_month = monthly_presence['presence_rate_pct'].idxmin()\n",
    "        print(f'  - Highest presence rate: Month {peak_month} ({monthly_presence.loc[peak_month, \"presence_rate_pct\"]:.1f}%)')\n",
    "        print(f'  - Lowest presence rate: Month {low_month} ({monthly_presence.loc[low_month, \"presence_rate_pct\"]:.1f}%)')\n",
    "        \n",
    "        if peak_month in [9, 10, 11]:  # Sep, Oct, Nov\n",
    "            print('  - Peak in fall months may indicate hunting season bias')\n",
    "        \n",
    "        print('\\n✓ Saved temporal pattern visualizations')\n",
    "    else:\n",
    "        print('⚠ Cannot analyze temporal patterns without month column')\n",
    "else:\n",
    "    print('⚠ Cannot analyze temporal patterns without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Presence Patterns by Space\n",
    "\n",
    "Spatial patterns in presence rate reveal geographic hotspots and potential spatial biases in the data. This section creates a heatmap of presence rate across the study area.\n",
    "\n",
    "### What This Code Does\n",
    "- Creates a hexbin map where color = presence rate within each hex\n",
    "- Uses red-yellow-green color scale (red = low presence rate, green = high)\n",
    "- Bins data into rough grid cells and calculates regional presence rates\n",
    "\n",
    "### Interpreting Spatial Presence Patterns\n",
    "\n",
    "**Color Scale:**\n",
    "- **Green areas (high presence rate)**: Elk hotspots - core habitat\n",
    "- **Yellow areas (moderate)**: Mixed use areas\n",
    "- **Red areas (low presence rate)**: Elk-poor areas or well-sampled absence areas\n",
    "\n",
    "**Expected Patterns:**\n",
    "- **Heterogeneous**: Mix of colors reflecting habitat variation (good)\n",
    "- **Study area clusters**: Different presence rates by region (expected)\n",
    "- **Elevation bands**: Higher rates at optimal elevations\n",
    "\n",
    "**Concerning Patterns:**\n",
    "- **Uniform green**: All areas have high presence - absence generation may be flawed\n",
    "- **Uniform red**: All areas have low presence - may have too many absences\n",
    "- **Stark boundaries**: Artificial edges may indicate data collection artifacts\n",
    "\n",
    "### What to Look For\n",
    "- **Known elk areas**: Should show higher presence rates\n",
    "- **Known poor habitat**: Should show lower presence rates\n",
    "- **Winter vs summer range**: May have different presence patterns\n",
    "- **Human development**: Should generally show lower presence rates\n",
    "\n",
    "### Implications for Modeling\n",
    "\n",
    "**Spatial Heterogeneity (good):**\n",
    "- Model can learn habitat features, not just locations\n",
    "- Validates that pseudo-absences create meaningful contrast\n",
    "\n",
    "**Spatial Autocorrelation (concern):**\n",
    "- Nearby locations have similar presence rates\n",
    "- May need spatial cross-validation\n",
    "- Consider spatial random effects in modeling\n",
    "\n",
    "### Elk Ecology Context\n",
    "Elk presence is inherently spatially clustered due to:\n",
    "1. **Habitat suitability**: Some areas simply have better habitat\n",
    "2. **Social behavior**: Elk are gregarious, forming herds\n",
    "3. **Predator avoidance**: Certain areas provide refuge\n",
    "4. **Human activity**: Elk avoid roads, development, hunting pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial patterns in presence\n",
    "if target_col:\n",
    "    # Detect lat/lon columns\n",
    "    lat_col = None\n",
    "    lon_col = None\n",
    "    for col in df.columns:\n",
    "        if 'lat' in col.lower() and 'lon' not in col.lower():\n",
    "            lat_col = col\n",
    "        if 'lon' in col.lower() and 'lat' not in col.lower():\n",
    "            lon_col = col\n",
    "    \n",
    "    if lat_col and lon_col:\n",
    "        # Create hexbin map of presence rate\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Sample if too many points\n",
    "        sample_size = min(50000, len(df))\n",
    "        df_sample = df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # Create hexbin plot colored by presence rate\n",
    "        hb = plt.hexbin(df_sample[lon_col], df_sample[lat_col], \n",
    "                       C=df_sample[target_col], gridsize=30, cmap='RdYlGn',\n",
    "                       reduce_C_function=np.mean, mincnt=10)\n",
    "        \n",
    "        plt.colorbar(hb, label='Presence Rate')\n",
    "        plt.xlabel('Longitude', fontsize=12)\n",
    "        plt.ylabel('Latitude', fontsize=12)\n",
    "        plt.title(f'Presence Rate Spatial Heatmap (n={sample_size:,} points)', fontsize=14, pad=20)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / 'presence_spatial_pattern.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print('✓ Saved spatial presence pattern')\n",
    "        \n",
    "        # Calculate presence rate by region (rough grid)\n",
    "        df['lat_bin'] = pd.cut(df[lat_col], bins=10, labels=False)\n",
    "        df['lon_bin'] = pd.cut(df[lon_col], bins=10, labels=False)\n",
    "        regional_presence = df.groupby(['lat_bin', 'lon_bin'])[target_col].agg(['mean', 'count'])\n",
    "        regional_presence.columns = ['presence_rate', 'count']\n",
    "        \n",
    "        print('\\n### Key Observations:')\n",
    "        high_regions = regional_presence[regional_presence['presence_rate'] > 0.6]\n",
    "        low_regions = regional_presence[regional_presence['presence_rate'] < 0.4]\n",
    "        print(f'  - High-presence regions (>60%): {len(high_regions)}')\n",
    "        print(f'  - Low-presence regions (<40%): {len(low_regions)}')\n",
    "        print(f'  - Spatial coverage: {df[[lat_col, lon_col]].drop_duplicates().shape[0]:,} unique locations')\n",
    "    else:\n",
    "        print('⚠ Cannot analyze spatial patterns without lat/lon columns')\n",
    "else:\n",
    "    print('⚠ Cannot analyze spatial patterns without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Distributions: Presence vs Absence\n",
    "\n",
    "Violin plots provide rich comparison of feature distributions between presence and absence classes, showing not just means but full distribution shapes including bimodality and outliers.\n",
    "\n",
    "### What This Code Does\n",
    "- Creates violin plots for top 12 features (by variance)\n",
    "- Shows full distribution shape for each class\n",
    "- Performs t-tests and calculates effect sizes (Cohen's d)\n",
    "- Identifies statistically significant differences\n",
    "\n",
    "### Interpreting Violin Plots\n",
    "\n",
    "**Violin Shape:**\n",
    "- **Width**: Indicates density of observations at that value\n",
    "- **Height**: Shows full range of values\n",
    "- **Widest point**: Mode (most common value)\n",
    "- **Thin necks**: Values where few observations exist\n",
    "\n",
    "**Comparing Classes:**\n",
    "- **Shifted violins**: Means differ (good discrimination)\n",
    "- **Different shapes**: Even with similar means, different distributions may be informative\n",
    "- **Overlapping violins**: Feature has limited discriminative power\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "**Strong Discriminators:**\n",
    "- Presence and absence violins clearly separated\n",
    "- Statistical test shows p < 0.01 AND |Cohen's d| > 0.5\n",
    "- Direction makes ecological sense\n",
    "\n",
    "**Weak Discriminators:**\n",
    "- Violins nearly identical\n",
    "- Large overlap despite statistical significance\n",
    "- Cohen's d near zero\n",
    "\n",
    "### Expected Directions (Presence vs Absence)\n",
    "\n",
    "| Feature | Expected Direction | Ecological Reason |\n",
    "|---------|-------------------|-------------------|\n",
    "| NDVI | Presence higher | Better forage |\n",
    "| Elevation | Presence optimal range | Thermal/forage trade-off |\n",
    "| Slope | Presence lower | Energy conservation |\n",
    "| Water distance | Presence lower | Water requirement |\n",
    "| Road distance | Presence higher | Human avoidance |\n",
    "| Snow depth | Variable by season | Movement constraint |\n",
    "\n",
    "### Using Results for Feature Selection\n",
    "- Features with clear separation: Include in model\n",
    "- Features with no separation: Consider dropping\n",
    "- Features with unexpected direction: Investigate data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plots comparing presence vs absence for each feature\n",
    "if target_col:\n",
    "    # Get numeric columns (exclude target and index columns)\n",
    "    numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                   if col not in [target_col, 'point_index', 'lat_bin', 'lon_bin']]\n",
    "    \n",
    "    # Select top 12 features by variance\n",
    "    feature_variance = df[numeric_cols].var().sort_values(ascending=False)\n",
    "    top_features = feature_variance.head(12).index.tolist()\n",
    "    \n",
    "    n_cols = 3\n",
    "    n_rows = (len(top_features) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for idx, col in enumerate(top_features):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        presence_data = df[df[target_col] == 1][col].dropna()\n",
    "        absence_data = df[df[target_col] == 0][col].dropna()\n",
    "        \n",
    "        if len(presence_data) > 0 and len(absence_data) > 0:\n",
    "            # Violin plots\n",
    "            data_to_plot = [presence_data, absence_data]\n",
    "            parts = ax.violinplot(data_to_plot, positions=[0, 1], showmeans=True, showmedians=True)\n",
    "            \n",
    "            # Color violins\n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor('steelblue')\n",
    "                pc.set_alpha(0.7)\n",
    "            \n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_xticklabels(['Presence', 'Absence'])\n",
    "            ax.set_ylabel(col, fontsize=10)\n",
    "            ax.set_title(col, fontsize=11)\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Statistical test\n",
    "            t_stat, p_value = ttest_ind(presence_data, absence_data)\n",
    "            mean_diff = presence_data.mean() - absence_data.mean()\n",
    "            \n",
    "            # Effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt((presence_data.std()**2 + absence_data.std()**2) / 2)\n",
    "            cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            test_results.append({\n",
    "                'feature': col,\n",
    "                'p_value': p_value,\n",
    "                'cohens_d': cohens_d,\n",
    "                'mean_diff': mean_diff,\n",
    "                'significant': p_value < 0.01\n",
    "            })\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(len(top_features), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Feature Distributions: Presence vs Absence (Violin Plots)', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'presence_feature_violins.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('✓ Saved violin plots')\n",
    "    \n",
    "    # Print statistical test results\n",
    "    if len(test_results) > 0:\n",
    "        results_df = pd.DataFrame(test_results).sort_values('p_value')\n",
    "        print('\\n### Statistical Test Results (sorted by p-value):')\n",
    "        print(results_df)\n",
    "        \n",
    "        significant = results_df[results_df['significant']]\n",
    "        print(f'\\n✓ {len(significant)} features show significant difference (p<0.01):')\n",
    "        for _, row in significant.head(10).iterrows():\n",
    "            print(f\"  - {row['feature']}: p={row['p_value']:.2e}, Cohen's d={row['cohens_d']:.2f}\")\n",
    "else:\n",
    "    print('⚠ Cannot compare feature distributions without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Presence Prediction Baseline\n",
    "\n",
    "Before building complex models, we establish baseline performance using simple strategies. Any useful model must outperform these baselines.\n",
    "\n",
    "### What This Code Does\n",
    "- **Baseline 1 (Random)**: Predicts presence/absence randomly (50/50)\n",
    "- **Baseline 2 (Majority)**: Always predicts the majority class\n",
    "- **Baseline 3 (Best Feature)**: Uses single best feature with threshold\n",
    "- Compares accuracy, precision, recall, and F1-score\n",
    "\n",
    "### Understanding Baselines\n",
    "\n",
    "**Random Guess (Baseline 1):**\n",
    "- Always achieves ~50% accuracy on binary classification\n",
    "- Sets absolute floor for performance\n",
    "- Any model worse than this is counterproductive\n",
    "\n",
    "**Majority Class (Baseline 2):**\n",
    "- If classes are 60/40, always predicting majority achieves 60%\n",
    "- This is the baseline for imbalanced data\n",
    "- Critical threshold for accuracy to be meaningful\n",
    "\n",
    "**Best Single Feature (Baseline 3):**\n",
    "- Uses feature with highest Cohen's d\n",
    "- Threshold at median of that feature\n",
    "- Shows what simple rule-based approach achieves\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "**Baseline 2 vs Baseline 3:**\n",
    "- If single feature beats majority baseline: Features have predictive power\n",
    "- If similar: Features may not be discriminative enough\n",
    "\n",
    "**Target Performance:**\n",
    "- Project goal is 70%+ accuracy\n",
    "- This means beating baselines by 10-20 percentage points\n",
    "- For imbalanced data, focus on F1-score instead\n",
    "\n",
    "### Setting Model Expectations\n",
    "\n",
    "| Metric | Baseline | Target | Excellent |\n",
    "|--------|----------|--------|-----------|\n",
    "| Accuracy | ~50-60% | 70%+ | 80%+ |\n",
    "| F1-Score | ~0.5 | 0.65+ | 0.75+ |\n",
    "| AUC-ROC | 0.5 | 0.70+ | 0.80+ |\n",
    "\n",
    "### Elk Ecology Context\n",
    "Baseline performance reflects the inherent difficulty of the prediction task:\n",
    "- Elk habitat selection involves many factors\n",
    "- Individual variation and stochasticity add noise\n",
    "- 70-80% accuracy is typical for species distribution models\n",
    "- Perfect prediction is not expected (or biologically meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple baseline models\n",
    "if target_col:\n",
    "    y_true = df[target_col].dropna()\n",
    "    \n",
    "    # Baseline 1: Random guess (50/50)\n",
    "    np.random.seed(42)\n",
    "    y_random = np.random.randint(0, 2, size=len(y_true))\n",
    "    acc_random = accuracy_score(y_true, y_random)\n",
    "    \n",
    "    # Baseline 2: Always predict majority class\n",
    "    majority_class = y_true.mode()[0]\n",
    "    y_majority = np.full(len(y_true), majority_class)\n",
    "    acc_majority = accuracy_score(y_true, y_majority)\n",
    "    \n",
    "    # Baseline 3: Best single feature (if we have test results)\n",
    "    best_feature_acc = 0\n",
    "    best_feature_name = None\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        # Use feature with highest |Cohen's d|\n",
    "        best_feature = results_df.loc[results_df['cohens_d'].abs().idxmax(), 'feature']\n",
    "        best_feature_name = best_feature\n",
    "        \n",
    "        # Create threshold-based classifier\n",
    "        presence_data = df[df[target_col] == 1][best_feature].dropna()\n",
    "        absence_data = df[df[target_col] == 0][best_feature].dropna()\n",
    "        \n",
    "        if len(presence_data) > 0 and len(absence_data) > 0:\n",
    "            threshold = (presence_data.median() + absence_data.median()) / 2\n",
    "            valid_mask = df[best_feature].notna() & df[target_col].notna()\n",
    "            y_feature = (df.loc[valid_mask, best_feature] > threshold).astype(int)\n",
    "            y_true_feature = df.loc[valid_mask, target_col]\n",
    "            \n",
    "            if len(y_feature) > 0:\n",
    "                best_feature_acc = accuracy_score(y_true_feature, y_feature)\n",
    "                prec_feature = precision_score(y_true_feature, y_feature, zero_division=0)\n",
    "                rec_feature = recall_score(y_true_feature, y_feature, zero_division=0)\n",
    "                f1_feature = f1_score(y_true_feature, y_feature, zero_division=0)\n",
    "    \n",
    "    # Print baseline results\n",
    "    print('### Baseline Model Performance:')\n",
    "    print(f'\\n1. Random Guess (50/50):')\n",
    "    print(f'   Accuracy: {acc_random:.3f}')\n",
    "    \n",
    "    print(f'\\n2. Always Predict Majority Class ({majority_class}):')\n",
    "    print(f'   Accuracy: {acc_majority:.3f}')\n",
    "    \n",
    "    if best_feature_name:\n",
    "        print(f'\\n3. Single Best Feature ({best_feature_name}):')\n",
    "        print(f'   Accuracy: {best_feature_acc:.3f}')\n",
    "        print(f'   Precision: {prec_feature:.3f}')\n",
    "        print(f'   Recall: {rec_feature:.3f}')\n",
    "        print(f'   F1-Score: {f1_feature:.3f}')\n",
    "    \n",
    "    # Create comparison bar chart\n",
    "    baseline_names = ['Random', 'Majority', 'Best Feature']\n",
    "    baseline_accs = [acc_random, acc_majority, best_feature_acc if best_feature_name else 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['red' if x < 0.6 else 'orange' if x < 0.7 else 'green' for x in baseline_accs]\n",
    "    bars = plt.bar(baseline_names, baseline_accs, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.axhline(0.7, color='green', linestyle='--', linewidth=2, label='Target (70%)')\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Baseline Model Performance Comparison', fontsize=14, pad=20)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, baseline_accs):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'baseline_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✓ Saved baseline performance comparison')\n",
    "    print(f'\\n### Recommendation:')\n",
    "    best_baseline = max(baseline_accs)\n",
    "    print(f'  ML models must achieve >{best_baseline:.3f} accuracy to be useful')\n",
    "    print(f'  Target accuracy: 70%+ (as specified in project goals)')\n",
    "else:\n",
    "    print('⚠ Cannot create baselines without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modeling Recommendations\n",
    "\n",
    "Based on the target variable analysis, this section generates comprehensive recommendations for model development including handling class imbalance, choosing evaluation metrics, and setting up train/test splits.\n",
    "\n",
    "### What This Code Does\n",
    "- Synthesizes findings from all previous sections\n",
    "- Generates prioritized recommendations by category\n",
    "- Saves detailed recommendations to `data/reports/modeling_recommendations.md`\n",
    "\n",
    "### Recommendation Categories\n",
    "\n",
    "**Class Imbalance:**\n",
    "- Based on observed imbalance ratio\n",
    "- Recommends appropriate handling techniques\n",
    "- Informs loss function and sampling strategy\n",
    "\n",
    "**Train/Test Split:**\n",
    "- Based on temporal patterns observed\n",
    "- Recommends temporal vs random split\n",
    "- Addresses potential data leakage\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Based on class balance and use case\n",
    "- Recommends primary and secondary metrics\n",
    "- Sets performance thresholds\n",
    "\n",
    "**Baseline Performance:**\n",
    "- Documents baselines that models must exceed\n",
    "- Sets minimum acceptable performance\n",
    "- Aligns with project goals (70% accuracy)\n",
    "\n",
    "### How to Use Recommendations\n",
    "\n",
    "1. **Review high-priority items first** - address before training any models\n",
    "2. **Set up evaluation framework** - decide metrics before comparing models\n",
    "3. **Document design choices** - record rationale for future reference\n",
    "4. **Iterate based on results** - adjust approach if initial models underperform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive modeling recommendations\n",
    "if target_col:\n",
    "    recommendations = []\n",
    "    \n",
    "    # Class imbalance recommendations\n",
    "    if 'imbalance_ratio' in locals():\n",
    "        if imbalance_ratio > 4:\n",
    "            recommendations.append({\n",
    "                'category': 'Class Imbalance',\n",
    "                'issue': f'Severe imbalance ({imbalance_ratio:.1f}:1)',\n",
    "                'recommendation': 'Use SMOTE oversampling or class weights in model',\n",
    "                'priority': 'HIGH'\n",
    "            })\n",
    "        elif imbalance_ratio > 2:\n",
    "            recommendations.append({\n",
    "                'category': 'Class Imbalance',\n",
    "                'issue': f'Moderate imbalance ({imbalance_ratio:.1f}:1)',\n",
    "                'recommendation': 'Consider class weights in model training',\n",
    "                'priority': 'MEDIUM'\n",
    "            })\n",
    "    \n",
    "    # Train/test split recommendations\n",
    "    if 'month_col' in locals() and month_col:\n",
    "        recommendations.append({\n",
    "            'category': 'Train/Test Split',\n",
    "            'issue': 'Temporal data with seasonal patterns',\n",
    "            'recommendation': 'Use temporal split (train on earlier years, test on later) or stratified by month',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'category': 'Train/Test Split',\n",
    "            'issue': 'No clear temporal structure',\n",
    "            'recommendation': 'Use stratified random split to maintain class balance',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "    \n",
    "    # Evaluation metrics recommendations\n",
    "    if 'imbalance_ratio' in locals() and imbalance_ratio > 2:\n",
    "        recommendations.append({\n",
    "            'category': 'Evaluation Metrics',\n",
    "            'issue': 'Class imbalance makes accuracy misleading',\n",
    "            'recommendation': 'Focus on F1-score, precision, recall, and AUC-ROC instead of accuracy',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'category': 'Evaluation Metrics',\n",
    "            'issue': 'Relatively balanced classes',\n",
    "            'recommendation': 'Accuracy is acceptable, but also track F1-score and AUC-ROC',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "    \n",
    "    # Baseline performance\n",
    "    if 'best_baseline' in locals():\n",
    "        recommendations.append({\n",
    "            'category': 'Baseline Performance',\n",
    "            'issue': f'Best baseline achieves {best_baseline:.3f} accuracy',\n",
    "            'recommendation': f'ML models must exceed {best_baseline:.3f} to be useful. Target: 70%+',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    \n",
    "    # Save recommendations\n",
    "    if len(recommendations) > 0:\n",
    "        rec_df = pd.DataFrame(recommendations)\n",
    "        \n",
    "        print('### Modeling Recommendations:')\n",
    "        print(rec_df.to_string(index=False))\n",
    "        \n",
    "        report = f'''# Modeling Recommendations for PathWild\n",
    "\n",
    "Generated: {pd.Timestamp.now()}\n",
    "\n",
    "## Summary\n",
    "\n",
    "Based on target variable analysis, the following recommendations are provided for model development.\n",
    "\n",
    "## Recommendations by Category\n",
    "\n",
    "'''\n",
    "        \n",
    "        for category in rec_df['category'].unique():\n",
    "            category_recs = rec_df[rec_df['category'] == category]\n",
    "            report += f'\\n### {category}\\n\\n'\n",
    "            for _, rec in category_recs.iterrows():\n",
    "                report += f'- **Priority**: {rec[\"priority\"]}\\n'\n",
    "                report += f'  - **Issue**: {rec[\"issue\"]}\\n'\n",
    "                report += f'  - **Recommendation**: {rec[\"recommendation\"]}\\n\\n'\n",
    "        \n",
    "        report += '''\n",
    "## Next Steps\n",
    "\n",
    "1. Address high-priority recommendations before model training\n",
    "2. Set up appropriate train/test split strategy\n",
    "3. Choose evaluation metrics based on class balance\n",
    "4. Establish baseline performance targets\n",
    "5. Proceed with feature engineering and model selection\n",
    "\n",
    "## Target Performance\n",
    "\n",
    "- **Minimum**: Exceed best baseline performance\n",
    "- **Target**: 70%+ accuracy (as specified in project goals)\n",
    "- **Metrics**: Track accuracy, F1-score, precision, recall, and AUC-ROC\n",
    "'''\n",
    "        \n",
    "        with open(reports_dir / 'modeling_recommendations.md', 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print('\\n✓ Saved recommendations to data/reports/modeling_recommendations.md')\n",
    "    else:\n",
    "        print('⚠ Could not generate recommendations')\n",
    "else:\n",
    "    print('⚠ Cannot generate recommendations without target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completed a comprehensive analysis of the target variable (elk presence/absence):\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Target Identification**: Confirmed binary target variable suitable for classification\n",
    "2. **Class Balance**: Assessed imbalance ratio and recommended handling approach\n",
    "3. **Temporal Patterns**: Examined presence rate variation by month/year\n",
    "4. **Spatial Patterns**: Mapped presence rate hotspots and coldspots\n",
    "5. **Feature Discrimination**: Identified features that separate presence from absence\n",
    "6. **Baseline Performance**: Established minimum performance thresholds\n",
    "\n",
    "### Saved Outputs\n",
    "\n",
    "- `data/reports/modeling_recommendations.md`: Comprehensive modeling guidance\n",
    "- `data/figures/class_balance.png`: Class distribution visualization\n",
    "- `data/figures/presence_temporal_pattern.png`: Monthly presence rate\n",
    "- `data/figures/presence_spatial_pattern.png`: Geographic presence heatmap\n",
    "- `data/figures/presence_feature_violins.png`: Feature discrimination plots\n",
    "- `data/figures/baseline_performance.png`: Baseline model comparison\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "With the exploratory data analysis complete (Notebooks 06-11), you are ready to:\n",
    "\n",
    "1. **Prepare training features** using `scripts/prepare_training_features.py`\n",
    "2. **Train baseline models** starting with logistic regression and random forest\n",
    "3. **Iterate on feature engineering** based on EDA insights\n",
    "4. **Validate with proper cross-validation** using recommended split strategy\n",
    "5. **Deploy best model** for inference pipeline\n",
    "\n",
    "### Key Recommendations for Modeling\n",
    "\n",
    "- Use **F1-score and AUC-ROC** as primary metrics (not just accuracy)\n",
    "- Apply **stratified splits** to maintain class balance in train/test\n",
    "- Consider **temporal validation** for realistic performance estimates\n",
    "- Start with **top 10-15 features** identified by target correlation\n",
    "- Use **tree-based models** (Random Forest, XGBoost) which handle non-linearity automatically"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
