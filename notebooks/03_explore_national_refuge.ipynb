{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploring National Elk Refuge GPS Collar Data (2006-2015)\n",
        "\n",
        "This notebook explores the National Elk Refuge GPS collar dataset - valuable for general elk behavior patterns and large sample size training!\n",
        "\n",
        "**Dataset Info:**\n",
        "- **Location:** National Elk Refuge, Jackson, Wyoming\n",
        "- **Coverage:** 17 adult female elk, 2006-2015\n",
        "- **Data:** GPS locations, timestamps, migration patterns\n",
        "- **Use Case:** General elk behavior patterns, seasonal timing, long time series\n",
        "- **Note:** ~200 miles from Area 048, but provides valuable general patterns\n",
        "\n",
        "**Download:** https://data.usgs.gov/datacatalog/data/USGS:5a9f2782e4b0b1c392e502ea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Set up paths\n",
        "DATA_DIR = Path(\"../data/raw\")\n",
        "REFUGE_DIR = DATA_DIR / \"elk_national_refuge\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NATIONAL ELK REFUGE DATASET\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nData directory: {REFUGE_DIR}\")\n",
        "print(f\"Directory exists: {REFUGE_DIR.exists()}\")\n",
        "\n",
        "# Look for data files\n",
        "if REFUGE_DIR.exists():\n",
        "    files = list(REFUGE_DIR.glob(\"*\"))\n",
        "    print(f\"\\nFiles found: {len(files)}\")\n",
        "    for f in files[:10]:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f  Directory doesn't exist yet!\")\n",
        "    print(\"\ud83d\udce5 Download instructions:\")\n",
        "    print(\"   1. Visit: https://data.usgs.gov/datacatalog/data/USGS:5a9f2782e4b0b1c392e502ea\")\n",
        "    print(\"   2. Download the dataset (CSV or shapefile format)\")\n",
        "    print(\"   3. Extract to: data/raw/elk_national_refuge/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the Data\n",
        "\n",
        "The dataset may be in CSV format (GPS points) or shapefile format. We'll try both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to find and load the data file\n",
        "csv_files = list(REFUGE_DIR.glob(\"*.csv\"))\n",
        "shp_files = list(REFUGE_DIR.glob(\"*.shp\"))\n",
        "\n",
        "if shp_files:\n",
        "    print(f\"Loading shapefile: {shp_files[0].name}\")\n",
        "    gdf = gpd.read_file(shp_files[0])\n",
        "    data_type = \"shapefile\"\n",
        "elif csv_files:\n",
        "    print(f\"Loading CSV: {csv_files[0].name}\")\n",
        "    df = pd.read_csv(csv_files[0])\n",
        "    \n",
        "    # Auto-detect lat/lon columns\n",
        "    lat_col = None\n",
        "    lon_col = None\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        if 'lat' in col_lower and lat_col is None:\n",
        "            lat_col = col\n",
        "        if ('lon' in col_lower or 'long' in col_lower) and lon_col is None:\n",
        "            lon_col = col\n",
        "    \n",
        "    if lat_col and lon_col:\n",
        "        print(f\"  Found coordinates: {lat_col}, {lon_col}\")\n",
        "        gdf = gpd.GeoDataFrame(\n",
        "            df,\n",
        "            geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
        "            crs='EPSG:4326'\n",
        "        )\n",
        "        data_type = \"csv_points\"\n",
        "    else:\n",
        "        print(f\"  \u26a0\ufe0f  Columns: {list(df.columns)}\")\n",
        "        print(\"  Please update the notebook to specify lat/lon column names.\")\n",
        "        gdf = None\n",
        "        data_type = None\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  No data files found!\")\n",
        "    gdf = None\n",
        "    data_type = None\n",
        "\n",
        "if gdf is not None:\n",
        "    print(f\"\\n\u2713 Data loaded: {data_type}, Shape: {gdf.shape}, CRS: {gdf.crs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Inspect Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if gdf is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATASET STRUCTURE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nShape: {gdf.shape}\")\n",
        "    print(f\"Columns: {list(gdf.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(gdf.head())\n",
        "    print(f\"\\nData types:\")\n",
        "    print(gdf.dtypes)\n",
        "    print(f\"\\nMissing values:\")\n",
        "    missing = gdf.isnull().sum()\n",
        "    if missing.sum() > 0:\n",
        "        for col, count in missing[missing > 0].items():\n",
        "            print(f\"  {col}: {count} ({count/len(gdf)*100:.1f}%)\")\n",
        "    else:\n",
        "        print(\"  \u2713 No missing values!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Extract Coordinates and Analyze Spatial Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if gdf is not None:\n",
        "    # Ensure we have lat/lon\n",
        "    if 'latitude' not in gdf.columns or 'longitude' not in gdf.columns:\n",
        "        if gdf.geometry is not None:\n",
        "            gdf_wgs84 = gdf.to_crs('EPSG:4326') if gdf.crs != 'EPSG:4326' else gdf\n",
        "            gdf_wgs84['latitude'] = gdf_wgs84.geometry.y\n",
        "            gdf_wgs84['longitude'] = gdf_wgs84.geometry.x\n",
        "        else:\n",
        "            gdf_wgs84 = None\n",
        "    else:\n",
        "        gdf_wgs84 = gdf.to_crs('EPSG:4326') if gdf.crs != 'EPSG:4326' else gdf\n",
        "    \n",
        "    if gdf_wgs84 is not None:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"SPATIAL COVERAGE\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\nLatitude: {gdf_wgs84['latitude'].min():.4f}\u00b0 to {gdf_wgs84['latitude'].max():.4f}\u00b0\")\n",
        "        print(f\"Longitude: {gdf_wgs84['longitude'].min():.4f}\u00b0 to {gdf_wgs84['longitude'].max():.4f}\u00b0\")\n",
        "        \n",
        "        # Distance to Area 048\n",
        "        area_048_lat, area_048_lon = 41.835, -106.425\n",
        "        \n",
        "        from math import radians, sin, cos, sqrt, atan2\n",
        "        \n",
        "        def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "            R = 6371  # Earth radius in km\n",
        "            lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "            c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
        "            return R * c\n",
        "        \n",
        "        gdf_wgs84['distance_to_area_048_km'] = gdf_wgs84.apply(\n",
        "            lambda row: haversine_distance(row['latitude'], row['longitude'], area_048_lat, area_048_lon),\n",
        "            axis=1\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nProximity to Area 048:\")\n",
        "        print(f\"  Min distance: {gdf_wgs84['distance_to_area_048_km'].min():.2f} km\")\n",
        "        print(f\"  Max distance: {gdf_wgs84['distance_to_area_048_km'].max():.2f} km\")\n",
        "        print(f\"  Avg distance: {gdf_wgs84['distance_to_area_048_km'].mean():.2f} km\")\n",
        "        print(f\"  Points within 200km: {(gdf_wgs84['distance_to_area_048_km'] <= 200).sum()} ({(gdf_wgs84['distance_to_area_048_km'] <= 200).sum() / len(gdf_wgs84) * 100:.1f}%)\")\n",
        "        print(f\"\\n\u26a0\ufe0f  Note: National Elk Refuge is ~200 miles from Area 048.\")\n",
        "        print(f\"   This data is valuable for general patterns, not geographic specificity.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Temporal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if gdf_wgs84 is not None:\n",
        "    # Try to find date column\n",
        "    date_col = None\n",
        "    for col in gdf_wgs84.columns:\n",
        "        if 'date' in col.lower() or 'time' in col.lower():\n",
        "            date_col = col\n",
        "            break\n",
        "    \n",
        "    if date_col:\n",
        "        try:\n",
        "            gdf_wgs84['date'] = pd.to_datetime(gdf_wgs84[date_col])\n",
        "            gdf_wgs84['year'] = gdf_wgs84['date'].dt.year\n",
        "            gdf_wgs84['month'] = gdf_wgs84['date'].dt.month\n",
        "            \n",
        "            print(\"=\" * 60)\n",
        "            print(\"TEMPORAL ANALYSIS\")\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"\\nDate range: {gdf_wgs84['date'].min()} to {gdf_wgs84['date'].max()}\")\n",
        "            \n",
        "            print(f\"\\nYear distribution:\")\n",
        "            for year, count in gdf_wgs84['year'].value_counts().sort_index().items():\n",
        "                print(f\"  {int(year)}: {count:,} points ({count/len(gdf_wgs84)*100:.1f}%)\")\n",
        "            \n",
        "            print(f\"\\nMonth distribution:\")\n",
        "            for month, count in gdf_wgs84['month'].value_counts().sort_index().items():\n",
        "                month_name = pd.to_datetime(f\"2020-{month}-01\").strftime(\"%B\")\n",
        "                print(f\"  {month_name}: {count:,} points ({count/len(gdf_wgs84)*100:.1f}%)\")\n",
        "            \n",
        "            # October analysis\n",
        "            october_points = gdf_wgs84[gdf_wgs84['month'] == 10]\n",
        "            print(f\"\\n\ud83c\udfaf October data: {len(october_points):,} points ({len(october_points)/len(gdf_wgs84)*100:.1f}%)\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f  Could not parse dates: {e}\")\n",
        "    else:\n",
        "        print(\"\u26a0\ufe0f  No date column found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prepare Data for PathWild Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if gdf_wgs84 is not None:\n",
        "    # Create PathWild-ready dataset\n",
        "    pathwild_data = pd.DataFrame({\n",
        "        'latitude': gdf_wgs84['latitude'],\n",
        "        'longitude': gdf_wgs84['longitude'],\n",
        "        'distance_to_area_048_km': gdf_wgs84['distance_to_area_048_km']\n",
        "    })\n",
        "    \n",
        "    # Add temporal info if available\n",
        "    if 'date' in gdf_wgs84.columns:\n",
        "        pathwild_data['date'] = gdf_wgs84['date']\n",
        "        pathwild_data['year'] = gdf_wgs84['year']\n",
        "        pathwild_data['month'] = gdf_wgs84['month']\n",
        "    \n",
        "    # Add other relevant columns\n",
        "    for col in gdf_wgs84.columns:\n",
        "        if col not in pathwild_data.columns and col not in ['geometry', 'latitude', 'longitude']:\n",
        "            if gdf_wgs84[col].dtype in ['int64', 'float64', 'object']:\n",
        "                pathwild_data[col] = gdf_wgs84[col]\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"PATHWILD-READY DATASET\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nShape: {pathwild_data.shape}\")\n",
        "    print(f\"Columns: {list(pathwild_data.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(pathwild_data.head())\n",
        "    \n",
        "    # Save to CSV\n",
        "    output_file = Path(\"../data/processed/national_refuge_points.csv\")\n",
        "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    pathwild_data.to_csv(output_file, index=False)\n",
        "    print(f\"\\n\u2713 Saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"NATIONAL ELK REFUGE DATASET SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTotal GPS points: {len(gdf_wgs84):,}\")\n",
        "    print(f\"\\nGeographic coverage:\")\n",
        "    print(f\"  Latitude: {gdf_wgs84['latitude'].min():.4f}\u00b0 to {gdf_wgs84['latitude'].max():.4f}\u00b0\")\n",
        "    print(f\"  Longitude: {gdf_wgs84['longitude'].min():.4f}\u00b0 to {gdf_wgs84['longitude'].max():.4f}\u00b0\")\n",
        "    print(f\"\\nProximity to Area 048:\")\n",
        "    print(f\"  Average distance: {gdf_wgs84['distance_to_area_048_km'].mean():.2f} km\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\udccb Key Insights:\")\n",
        "    print(f\"  \u2713 Large sample size for general elk behavior patterns\")\n",
        "    print(f\"  \u2713 Long time series (2006-2015)\")\n",
        "    print(f\"  \u2713 Useful for understanding seasonal timing\")\n",
        "    print(f\"  \u26a0\ufe0f  Geographic distance from Area 048 (~200 miles)\")\n",
        "    print(f\"  \u2192 Best used for general patterns, not geographic specificity\")\n",
        "    \n",
        "    print(f\"\\nNext steps:\")\n",
        "    print(\"  1. Combine with South Bighorn data for hybrid training\")\n",
        "    print(\"  2. Use for general elk behavior patterns\")\n",
        "    print(\"  3. Integrate with DataContextBuilder to add environmental features\")\n",
        "    print(\"  4. Create training dataset with positive examples (GPS points)\")\n",
        "    print(\"  5. Generate negative examples (random points)\")\n",
        "    print(\"  6. Train XGBoost model with weighted combination of datasets\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}