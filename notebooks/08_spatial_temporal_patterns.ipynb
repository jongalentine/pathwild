{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 8: Spatial-Temporal Patterns\n",
        "\n",
        "## Purpose\n",
        "Visualize geographic and temporal patterns in the PathWild elk data.\n",
        "\n",
        "## Key Questions\n",
        "- Is spatial coverage uniform or clustered?\n",
        "- Do elk show seasonal migration patterns?\n",
        "- Are there spatial hotspots for elk presence?\n",
        "- Do features show expected seasonal cycles?\n",
        "\n",
        "## Key Observations to Look For\n",
        "- **Spatial Clustering**: Elk observations should cluster in known habitat areas\n",
        "- **Seasonal Migration**: Elevation changes in winter (lower) vs summer (higher)\n",
        "- **NDVI Patterns**: Should correlate with vegetation zones\n",
        "- **Temporal Autocorrelation**: Could affect train/test splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Determine project root and output directories\n",
        "possible_roots = [\n",
        "    Path('.'),  # If running from project root\n",
        "    Path('..'),  # If running from notebooks directory\n",
        "    Path('../..'),  # If running from subdirectory\n",
        "]\n",
        "\n",
        "data_root = None\n",
        "for root in possible_roots:\n",
        "    if (root / 'data' / 'features').exists():\n",
        "        data_root = root / 'data'\n",
        "        break\n",
        "\n",
        "if data_root is None:\n",
        "    data_root = Path('../data')\n",
        "\n",
        "# Create output directories relative to project root\n",
        "figures_dir = data_root / 'figures'\n",
        "reports_dir = data_root / 'reports'\n",
        "figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "reports_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f'✓ Setup complete')\n",
        "print(f'  Output directory: {data_root.absolute()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data and Detect Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('data/features/complete_context.csv')\n",
        "\n",
        "# Detect key columns\n",
        "timestamp_col = None\n",
        "lat_col = None\n",
        "lon_col = None\n",
        "presence_col = None\n",
        "ndvi_col = None\n",
        "elevation_col = None\n",
        "\n",
        "for col in df.columns:\n",
        "    if any(x in col.lower() for x in ['timestamp', 'date', 'time']):\n",
        "        timestamp_col = col\n",
        "    if 'lat' in col.lower() and 'lon' not in col.lower():\n",
        "        lat_col = col\n",
        "    if 'lon' in col.lower() and 'lat' not in col.lower():\n",
        "        lon_col = col\n",
        "    if col.lower() in ['presence', 'target', 'label', 'is_presence']:\n",
        "        presence_col = col\n",
        "    if 'ndvi' in col.lower():\n",
        "        ndvi_col = col\n",
        "    if 'elev' in col.lower() or 'altitude' in col.lower():\n",
        "        elevation_col = col\n",
        "\n",
        "if timestamp_col:\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors='coerce')\n",
        "    df['month'] = df[timestamp_col].dt.month\n",
        "    df['year'] = df[timestamp_col].dt.year\n",
        "\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(f'Timestamp: {timestamp_col}')\n",
        "print(f'Latitude: {lat_col}')\n",
        "print(f'Longitude: {lon_col}')\n",
        "print(f'Presence: {presence_col}')\n",
        "print(f'NDVI: {ndvi_col}')\n",
        "print(f'Elevation: {elevation_col}')\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Static Spatial Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create scatter plot of GPS points\n",
        "if lat_col and lon_col:\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    \n",
        "    # Sample if too many points\n",
        "    sample_size = min(20000, len(df))\n",
        "    df_sample = df.sample(n=sample_size, random_state=42)\n",
        "    \n",
        "    # Color by presence if available\n",
        "    if presence_col:\n",
        "        colors = df_sample[presence_col].map({1: 'blue', 0: 'red', True: 'blue', False: 'red'})\n",
        "        plt.scatter(\n",
        "            df_sample[lon_col],\n",
        "            df_sample[lat_col],\n",
        "            c=colors,\n",
        "            alpha=0.3,\n",
        "            s=5,\n",
        "            edgecolors='none'\n",
        "        )\n",
        "        \n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [\n",
        "            Patch(facecolor='blue', alpha=0.5, label=f'Presence (n={(df[presence_col]==1).sum():,})'),\n",
        "            Patch(facecolor='red', alpha=0.5, label=f'Absence (n={(df[presence_col]==0).sum():,})')\n",
        "        ]\n",
        "        plt.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
        "    else:\n",
        "        plt.scatter(\n",
        "            df_sample[lon_col],\n",
        "            df_sample[lat_col],\n",
        "            alpha=0.3,\n",
        "            s=5,\n",
        "            color='blue',\n",
        "            edgecolors='none'\n",
        "        )\n",
        "    \n",
        "    plt.xlabel('Longitude', fontsize=12)\n",
        "    plt.ylabel('Latitude', fontsize=12)\n",
        "    plt.title(f'Spatial Coverage Map (n={sample_size:,} points)', fontsize=14, pad=20)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'spatial_coverage.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved spatial coverage map')\n",
        "else:\n",
        "    print('⚠ Cannot create spatial map without lat/lon columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. NDVI Spatial Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create NDVI spatial heatmap\n",
        "if ndvi_col and lat_col and lon_col:\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    \n",
        "    # Filter to valid NDVI values\n",
        "    df_ndvi = df[[lon_col, lat_col, ndvi_col]].dropna()\n",
        "    \n",
        "    # Sample if too large\n",
        "    if len(df_ndvi) > 50000:\n",
        "        df_ndvi = df_ndvi.sample(n=50000, random_state=42)\n",
        "    \n",
        "    # Create hexbin plot\n",
        "    hexbin = plt.hexbin(\n",
        "        df_ndvi[lon_col],\n",
        "        df_ndvi[lat_col],\n",
        "        C=df_ndvi[ndvi_col],\n",
        "        gridsize=50,\n",
        "        cmap='RdYlGn',\n",
        "        reduce_C_function=np.mean,\n",
        "        mincnt=1\n",
        "    )\n",
        "    \n",
        "    plt.colorbar(hexbin, label='Mean NDVI')\n",
        "    plt.xlabel('Longitude', fontsize=12)\n",
        "    plt.ylabel('Latitude', fontsize=12)\n",
        "    plt.title('NDVI Spatial Distribution (Hexbin)', fontsize=14, pad=20)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'ndvi_spatial_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved NDVI spatial heatmap')\n",
        "    \n",
        "    # Statistics by region\n",
        "    print('\\nNDVI statistics by region:')\n",
        "    print(f'  Overall mean: {df_ndvi[ndvi_col].mean():.3f}')\n",
        "    print(f'  Overall std: {df_ndvi[ndvi_col].std():.3f}')\n",
        "else:\n",
        "    print('⚠ Cannot create NDVI heatmap without NDVI and lat/lon columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Temporal Line Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot temporal patterns for all numeric features\n",
        "if timestamp_col:\n",
        "    # Select features for temporal analysis (exclude month, year, lat, lon)\n",
        "    temporal_features = [col for col in numeric_cols \n",
        "                        if col not in ['month', 'year', lat_col, lon_col]][:12]\n",
        "    \n",
        "    n_cols = 3\n",
        "    n_rows = (len(temporal_features) + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
        "    \n",
        "    for idx, col in enumerate(temporal_features):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Group by date and calculate daily mean\n",
        "        daily_mean = df.groupby(df[timestamp_col].dt.date)[col].mean()\n",
        "        \n",
        "        # Plot with rolling average\n",
        "        ax.plot(daily_mean.index, daily_mean.values, alpha=0.3, color='gray', linewidth=0.5)\n",
        "        \n",
        "        # 7-day rolling average\n",
        "        rolling = daily_mean.rolling(window=7, center=True).mean()\n",
        "        ax.plot(rolling.index, rolling.values, color='blue', linewidth=2, label='7-day avg')\n",
        "        \n",
        "        ax.set_xlabel('Date', fontsize=9)\n",
        "        ax.set_ylabel(col, fontsize=9)\n",
        "        ax.set_title(col, fontsize=10)\n",
        "        ax.legend(fontsize=8)\n",
        "        ax.grid(alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
        "    \n",
        "    # Hide extra subplots\n",
        "    for idx in range(len(temporal_features), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Temporal Patterns (Daily Means with 7-day Rolling Average)', fontsize=16, y=1.00)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'temporal_timeseries.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved temporal timeseries')\n",
        "else:\n",
        "    print('⚠ Cannot create temporal plots without timestamp column')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Month vs Feature Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create heatmap showing seasonal patterns\n",
        "if timestamp_col and 'month' in df.columns:\n",
        "    # Select features for heatmap\n",
        "    heatmap_features = [col for col in numeric_cols \n",
        "                       if col not in ['month', 'year', lat_col, lon_col]][:20]\n",
        "    \n",
        "    # Calculate monthly means\n",
        "    monthly_data = df.groupby('month')[heatmap_features].mean()\n",
        "    \n",
        "    # Normalize each feature (0-1 scale) for better visualization\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    monthly_normalized = pd.DataFrame(\n",
        "        scaler.fit_transform(monthly_data.T).T,\n",
        "        index=monthly_data.index,\n",
        "        columns=monthly_data.columns\n",
        "    )\n",
        "    \n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.heatmap(\n",
        "        monthly_normalized.T,\n",
        "        cmap='RdYlGn',\n",
        "        cbar_kws={'label': 'Normalized Value (0-1)'},\n",
        "        xticklabels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
        "        yticklabels=monthly_normalized.columns\n",
        "    )\n",
        "    plt.xlabel('Month', fontsize=12)\n",
        "    plt.ylabel('Feature', fontsize=12)\n",
        "    plt.title('Seasonal Heatmap (Normalized Monthly Means)', fontsize=14, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'seasonal_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved seasonal heatmap')\n",
        "else:\n",
        "    print('⚠ Cannot create seasonal heatmap without timestamp column')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Spatial Clustering Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate kernel density estimate of elk observations\n",
        "if lat_col and lon_col and presence_col:\n",
        "    # Filter to presence observations\n",
        "    presence_df = df[df[presence_col] == 1][[lat_col, lon_col]].dropna()\n",
        "    absence_df = df[df[presence_col] == 0][[lat_col, lon_col]].dropna()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    \n",
        "    # Presence density\n",
        "    if len(presence_df) > 0:\n",
        "        sample_size = min(10000, len(presence_df))\n",
        "        presence_sample = presence_df.sample(n=sample_size, random_state=42)\n",
        "        \n",
        "        axes[0].hexbin(\n",
        "            presence_sample[lon_col],\n",
        "            presence_sample[lat_col],\n",
        "            gridsize=40,\n",
        "            cmap='Blues',\n",
        "            mincnt=1\n",
        "        )\n",
        "        axes[0].set_xlabel('Longitude', fontsize=12)\n",
        "        axes[0].set_ylabel('Latitude', fontsize=12)\n",
        "        axes[0].set_title(f'Elk Presence Density (n={len(presence_df):,})', fontsize=13)\n",
        "        axes[0].grid(alpha=0.3)\n",
        "    \n",
        "    # Absence density\n",
        "    if len(absence_df) > 0:\n",
        "        sample_size = min(10000, len(absence_df))\n",
        "        absence_sample = absence_df.sample(n=sample_size, random_state=42)\n",
        "        \n",
        "        axes[1].hexbin(\n",
        "            absence_sample[lon_col],\n",
        "            absence_sample[lat_col],\n",
        "            gridsize=40,\n",
        "            cmap='Reds',\n",
        "            mincnt=1\n",
        "        )\n",
        "        axes[1].set_xlabel('Longitude', fontsize=12)\n",
        "        axes[1].set_ylabel('Latitude', fontsize=12)\n",
        "        axes[1].set_title(f'Pseudo-Absence Density (n={len(absence_df):,})', fontsize=13)\n",
        "        axes[1].grid(alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'elk_density_contours.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved density contours')\n",
        "else:\n",
        "    print('⚠ Cannot create density plots without lat/lon and presence columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Elevation vs Time (Migration Pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze elevation changes over time\n",
        "if elevation_col and timestamp_col:\n",
        "    # Sample for visualization\n",
        "    sample_size = min(50000, len(df))\n",
        "    df_sample = df.sample(n=sample_size, random_state=42)\n",
        "    \n",
        "    plt.figure(figsize=(14, 8))\n",
        "    \n",
        "    # Color by presence if available\n",
        "    if presence_col:\n",
        "        colors = df_sample[presence_col].map({1: 'blue', 0: 'red', True: 'blue', False: 'red'})\n",
        "        plt.scatter(\n",
        "            df_sample[timestamp_col],\n",
        "            df_sample[elevation_col],\n",
        "            c=colors,\n",
        "            alpha=0.2,\n",
        "            s=10,\n",
        "            edgecolors='none'\n",
        "        )\n",
        "        \n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [\n",
        "            Patch(facecolor='blue', alpha=0.5, label='Presence'),\n",
        "            Patch(facecolor='red', alpha=0.5, label='Absence')\n",
        "        ]\n",
        "        plt.legend(handles=legend_elements, loc='upper right')\n",
        "    else:\n",
        "        plt.scatter(\n",
        "            df_sample[timestamp_col],\n",
        "            df_sample[elevation_col],\n",
        "            alpha=0.2,\n",
        "            s=10,\n",
        "            color='blue',\n",
        "            edgecolors='none'\n",
        "        )\n",
        "    \n",
        "    # Add monthly trend lines\n",
        "    if 'month' in df.columns:\n",
        "        monthly_elev = df.groupby('month')[elevation_col].mean()\n",
        "        # Create date proxies for plotting\n",
        "        month_dates = pd.date_range(start=df[timestamp_col].min(), periods=12, freq='MS')\n",
        "        plt.plot(month_dates[:len(monthly_elev)], monthly_elev.values, \n",
        "                color='black', linewidth=3, label='Monthly Mean', alpha=0.7)\n",
        "    \n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Elevation (ft)', fontsize=12)\n",
        "    plt.title('Elevation vs Time (Potential Migration Pattern)', fontsize=14, pad=20)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(figures_dir / 'elevation_vs_time.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print('✓ Saved elevation vs time plot')\n",
        "    \n",
        "    # Analyze seasonal elevation patterns\n",
        "    if 'month' in df.columns:\n",
        "        print('\\nSeasonal elevation statistics:')\n",
        "        seasonal_elev = df.groupby('month')[elevation_col].agg(['mean', 'std', 'count'])\n",
        "        print(seasonal_elev)\n",
        "        \n",
        "        winter_elev = df[df['month'].isin([12, 1, 2])][elevation_col].mean()\n",
        "        summer_elev = df[df['month'].isin([6, 7, 8])][elevation_col].mean()\n",
        "        elev_diff = summer_elev - winter_elev\n",
        "        \n",
        "        print(f'\\nWinter (Dec-Feb) mean elevation: {winter_elev:.1f} ft')\n",
        "        print(f'Summer (Jun-Aug) mean elevation: {summer_elev:.1f} ft')\n",
        "        print(f'Seasonal difference: {elev_diff:.1f} ft')\n",
        "        \n",
        "        if elev_diff > 500:\n",
        "            print('✓ Evidence of seasonal migration (elk move to higher elevations in summer)')\n",
        "        else:\n",
        "            print('⚠ Limited evidence of seasonal migration')\n",
        "else:\n",
        "    print('⚠ Cannot analyze elevation patterns without elevation and timestamp columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Temporal Autocorrelation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze temporal autocorrelation\n",
        "if timestamp_col:\n",
        "    # Select a few key features for autocorrelation analysis\n",
        "    acf_features = [col for col in [ndvi_col, elevation_col, 'temperature', 'precipitation']\n",
        "                   if col in df.columns][:4]\n",
        "    \n",
        "    if len(acf_features) > 0:\n",
        "        try:\n",
        "            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "            \n",
        "            fig, axes = plt.subplots(len(acf_features), 2, figsize=(14, 4*len(acf_features)))\n",
        "            if len(acf_features) == 1:\n",
        "                axes = axes.reshape(1, -1)\n",
        "            \n",
        "            for idx, col in enumerate(acf_features):\n",
        "                # Get time series data\n",
        "                ts_data = df.sort_values(timestamp_col)[col].dropna()\n",
        "                \n",
        "                # Limit to reasonable size for ACF\n",
        "                if len(ts_data) > 10000:\n",
        "                    ts_data = ts_data.iloc[:10000]\n",
        "                \n",
        "                # ACF plot\n",
        "                plot_acf(ts_data, lags=40, ax=axes[idx, 0], alpha=0.05)\n",
        "                axes[idx, 0].set_title(f'{col} - Autocorrelation', fontsize=11)\n",
        "                axes[idx, 0].grid(alpha=0.3)\n",
        "                \n",
        "                # PACF plot\n",
        "                plot_pacf(ts_data, lags=40, ax=axes[idx, 1], alpha=0.05)\n",
        "                axes[idx, 1].set_title(f'{col} - Partial Autocorrelation', fontsize=11)\n",
        "                axes[idx, 1].grid(alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.savefig(figures_dir / 'temporal_autocorrelation.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            \n",
        "            print('✓ Saved temporal autocorrelation plots')\n",
        "            print('\\nInterpretation:')\n",
        "            print('- Significant lags indicate temporal dependence')\n",
        "            print('- May need to account for this in train/test splitting')\n",
        "            print('- Consider time-based cross-validation')\n",
        "        except ImportError:\n",
        "            print('⚠ statsmodels not available for ACF/PACF plots')\n",
        "        except Exception as e:\n",
        "            print(f'⚠ Could not create ACF/PACF plots: {e}')\n",
        "    else:\n",
        "        print('⚠ No suitable features found for autocorrelation analysis')\n",
        "else:\n",
        "    print('⚠ Cannot analyze autocorrelation without timestamp column')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook analyzed spatial and temporal patterns:\n",
        "\n",
        "1. **Spatial Coverage**: Visualized GPS point distribution\n",
        "2. **NDVI Spatial Patterns**: Identified vegetation zones\n",
        "3. **Temporal Patterns**: Examined feature changes over time\n",
        "4. **Seasonal Heatmap**: Revealed seasonal cycles across features\n",
        "5. **Spatial Clustering**: Identified elk presence hotspots\n",
        "6. **Migration Patterns**: Analyzed elevation changes by season\n",
        "7. **Temporal Autocorrelation**: Assessed time-series dependencies\n",
        "\n",
        "**Key Findings**:\n",
        "- Review spatial clustering to validate pseudo-absence generation\n",
        "- Check for seasonal migration patterns in elevation data\n",
        "- Consider temporal autocorrelation for model validation strategy\n",
        "\n",
        "**Next Steps**:\n",
        "- Proceed to Notebook 09 for feature correlation analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
