{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploring Southern GYE Elk GPS Collar Data (2007-2015)\n",
        "\n",
        "This notebook explores the Southern Greater Yellowstone Ecosystem GPS collar dataset - excellent for large sample size training!\n",
        "\n",
        "**Dataset Info:**\n",
        "- **Location:** 22 Wyoming winter supplemental feedgrounds\n",
        "- **Coverage:** 288 adult and yearling female elk, 2007-2015\n",
        "- **Data:** GPS locations during brucellosis risk period (February-July)\n",
        "- **Use Case:** Large sample size, diverse conditions, statistical robustness\n",
        "- **Note:** ~200 miles from Area 048, but provides excellent training data\n",
        "\n",
        "**Data Format:** UTM coordinates (Easting/Northing) in Zone 12N - will be converted to lat/lon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SOUTHERN GYE DATASET\n",
            "============================================================\n",
            "\n",
            "Data directory: ../data/raw/elk_southern_gye\n",
            "Directory exists: True\n",
            "\n",
            "CSV files found: 1\n",
            "  - Elk GPS collar data in southern GYE 2007-2015.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from shapely.geometry import Point\n",
        "import pyproj\n",
        "\n",
        "# Set up paths\n",
        "DATA_DIR = Path(\"../data/raw\")\n",
        "GYE_DIR = DATA_DIR / \"elk_southern_gye\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SOUTHERN GYE DATASET\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nData directory: {GYE_DIR}\")\n",
        "print(f\"Directory exists: {GYE_DIR.exists()}\")\n",
        "\n",
        "# Look for data files\n",
        "if GYE_DIR.exists():\n",
        "    files = list(GYE_DIR.glob(\"*.csv\"))\n",
        "    print(f\"\\nCSV files found: {len(files)}\")\n",
        "    for f in files:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Directory doesn't exist yet!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the Data\n",
        "\n",
        "The dataset uses **UTM coordinates** (Easting/Northing) in Zone 12N. We'll convert these to lat/lon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: Elk GPS collar data in southern GYE 2007-2015.csv\n",
            "\n",
            "‚úì Data loaded successfully!\n",
            "  Shape: (94591, 5)\n",
            "  Columns: ['AID', 'Easting', 'Northing', 'Date_Time_MST', 'Feedground']\n",
            "\n",
            "First few rows:\n",
            "   AID      Easting     Northing    Date_Time_MST    Feedground\n",
            "0   17  570434.7207  4727340.258   3/21/2008 4:00  Bench_Corral\n",
            "1   17  570435.9304  4727881.330   3/21/2008 8:00  Bench_Corral\n",
            "2   17  569890.9708  4727580.732  3/21/2008 12:00  Bench_Corral\n",
            "3   17  572112.5855  4731880.513   3/22/2008 4:00  Bench_Corral\n",
            "4   17  571634.1351  4731804.016   3/22/2008 8:00  Bench_Corral\n",
            "\n",
            "Column check:\n",
            "  ‚úì AID\n",
            "  ‚úì Easting\n",
            "  ‚úì Northing\n",
            "  ‚úì Date_Time_MST\n",
            "  ‚úì Feedground\n"
          ]
        }
      ],
      "source": [
        "# Find and load the CSV file\n",
        "csv_files = list(GYE_DIR.glob(\"*.csv\"))\n",
        "\n",
        "if csv_files:\n",
        "    csv_file = csv_files[0]\n",
        "    print(f\"Loading: {csv_file.name}\")\n",
        "    df = pd.read_csv(csv_file)\n",
        "    \n",
        "    print(f\"\\n‚úì Data loaded successfully!\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    print(f\"  Columns: {list(df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    # Expected columns: AID, Easting, Northing, Date_Time_MST, Feedground\n",
        "    print(f\"\\nColumn check:\")\n",
        "    expected_cols = ['AID', 'Easting', 'Northing', 'Date_Time_MST', 'Feedground']\n",
        "    for col in expected_cols:\n",
        "        if col in df.columns:\n",
        "            print(f\"  ‚úì {col}\")\n",
        "        else:\n",
        "            print(f\"  ‚úó {col} (missing)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No CSV files found!\")\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Convert UTM Coordinates to Lat/Lon\n",
        "\n",
        "The data uses UTM Zone 12N coordinates. We'll convert to WGS84 (lat/lon) for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CONVERTING UTM TO LAT/LON\n",
            "============================================================\n",
            "\n",
            "UTM Zone: 12N\n",
            "Converting 94,591 points...\n",
            "\n",
            "‚úì Conversion complete!\n",
            "\n",
            "Sample converted coordinates:\n",
            "  UTM: Easting=570434.72, Northing=4727340.26\n",
            "  WGS84: Lat=42.6953¬∞, Lon=-110.1401¬∞\n",
            "\n",
            "Coordinate ranges:\n",
            "  Latitude: 42.5352¬∞ to 44.2879¬∞\n",
            "  Longitude: -111.0527¬∞ to -109.1663¬∞\n"
          ]
        }
      ],
      "source": [
        "if df is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"CONVERTING UTM TO LAT/LON\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # UTM Zone 12N (Wyoming)\n",
        "    utm_zone = 12\n",
        "    utm_crs = f'EPSG:326{utm_zone}'  # UTM Zone 12N\n",
        "    wgs84_crs = 'EPSG:4326'  # WGS84 lat/lon\n",
        "    \n",
        "    print(f\"\\nUTM Zone: {utm_zone}N\")\n",
        "    print(f\"Converting {len(df):,} points...\")\n",
        "    \n",
        "    # Create GeoDataFrame from UTM coordinates\n",
        "    gdf_utm = gpd.GeoDataFrame(\n",
        "        df,\n",
        "        geometry=gpd.points_from_xy(df['Easting'], df['Northing']),\n",
        "        crs=utm_crs\n",
        "    )\n",
        "    \n",
        "    # Convert to WGS84 (lat/lon)\n",
        "    gdf_wgs84 = gdf_utm.to_crs(wgs84_crs)\n",
        "    \n",
        "    # Extract lat/lon\n",
        "    gdf_wgs84['latitude'] = gdf_wgs84.geometry.y\n",
        "    gdf_wgs84['longitude'] = gdf_wgs84.geometry.x\n",
        "    \n",
        "    print(f\"\\n‚úì Conversion complete!\")\n",
        "    print(f\"\\nSample converted coordinates:\")\n",
        "    print(f\"  UTM: Easting={df['Easting'].iloc[0]:.2f}, Northing={df['Northing'].iloc[0]:.2f}\")\n",
        "    print(f\"  WGS84: Lat={gdf_wgs84['latitude'].iloc[0]:.4f}¬∞, Lon={gdf_wgs84['longitude'].iloc[0]:.4f}¬∞\")\n",
        "    \n",
        "    # Verify coordinates are in Wyoming range\n",
        "    lat_range = (gdf_wgs84['latitude'].min(), gdf_wgs84['latitude'].max())\n",
        "    lon_range = (gdf_wgs84['longitude'].min(), gdf_wgs84['longitude'].max())\n",
        "    print(f\"\\nCoordinate ranges:\")\n",
        "    print(f\"  Latitude: {lat_range[0]:.4f}¬∞ to {lat_range[1]:.4f}¬∞\")\n",
        "    print(f\"  Longitude: {lon_range[0]:.4f}¬∞ to {lon_range[1]:.4f}¬∞\")\n",
        "    \n",
        "    if 41 <= lat_range[0] <= 45 and -111 <= lon_range[0] <= -104:\n",
        "        print(f\"  ‚úì Coordinates are in Wyoming range\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Inspect Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATASET STRUCTURE\n",
            "============================================================\n",
            "\n",
            "Shape: (94591, 8)\n",
            "Columns: ['AID', 'Easting', 'Northing', 'Date_Time_MST', 'Feedground', 'geometry', 'latitude', 'longitude']\n",
            "\n",
            "Data types:\n",
            "AID                 int64\n",
            "Easting           float64\n",
            "Northing          float64\n",
            "Date_Time_MST      object\n",
            "Feedground         object\n",
            "geometry         geometry\n",
            "latitude          float64\n",
            "longitude         float64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "  ‚úì No missing values!\n",
            "\n",
            "Unique values:\n",
            "  Unique elk (AID): 288\n",
            "  Unique feedgrounds: 20\n",
            "  Feedgrounds: ['Bench_Corral', 'Black_Butte', 'Camp_Creek', 'Dell_Creek', 'Dog_Creek', 'Fall_Creek', 'Finnegan', 'Forest_Park', 'Franz', 'Green_River_Lakes', 'Greys_River', 'Gros_Ventre', 'Horse_Creek', 'Jewett', 'McNeel', 'Muddy_Creek', 'National_Elk_Refuge', 'Scab_Creek', 'Soda_Lake', 'South_Park']\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATASET STRUCTURE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nShape: {gdf_wgs84.shape}\")\n",
        "    print(f\"Columns: {list(gdf_wgs84.columns)}\")\n",
        "    print(f\"\\nData types:\")\n",
        "    print(gdf_wgs84.dtypes)\n",
        "    print(f\"\\nMissing values:\")\n",
        "    missing = gdf_wgs84.isnull().sum()\n",
        "    if missing.sum() > 0:\n",
        "        for col, count in missing[missing > 0].items():\n",
        "            print(f\"  {col}: {count} ({count/len(gdf_wgs84)*100:.1f}%)\")\n",
        "    else:\n",
        "        print(\"  ‚úì No missing values!\")\n",
        "    \n",
        "    print(f\"\\nUnique values:\")\n",
        "    print(f\"  Unique elk (AID): {gdf_wgs84['AID'].nunique()}\")\n",
        "    print(f\"  Unique feedgrounds: {gdf_wgs84['Feedground'].nunique()}\")\n",
        "    print(f\"  Feedgrounds: {sorted(gdf_wgs84['Feedground'].unique())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Spatial Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SPATIAL COVERAGE\n",
            "============================================================\n",
            "\n",
            "Latitude: 42.5352¬∞ to 44.2879¬∞\n",
            "Longitude: -111.0527¬∞ to -109.1663¬∞\n",
            "\n",
            "Proximity to Area 048:\n",
            "  Min distance: 244.09 km\n",
            "  Max distance: 435.00 km\n",
            "  Avg distance: 353.23 km\n",
            "  Points within 200km: 0 (0.0%)\n",
            "\n",
            "‚ö†Ô∏è  Note: Southern GYE is ~200 miles from Area 048.\n",
            "   This data is valuable for large sample size training.\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SPATIAL COVERAGE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nLatitude: {gdf_wgs84['latitude'].min():.4f}¬∞ to {gdf_wgs84['latitude'].max():.4f}¬∞\")\n",
        "    print(f\"Longitude: {gdf_wgs84['longitude'].min():.4f}¬∞ to {gdf_wgs84['longitude'].max():.4f}¬∞\")\n",
        "    \n",
        "    # Distance to Area 048\n",
        "    area_048_lat, area_048_lon = 41.835, -106.425\n",
        "    \n",
        "    from math import radians, sin, cos, sqrt, atan2\n",
        "    \n",
        "    def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "        R = 6371  # Earth radius in km\n",
        "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "        dlat = lat2 - lat1\n",
        "        dlon = lon2 - lon1\n",
        "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
        "        return R * c\n",
        "    \n",
        "    gdf_wgs84['distance_to_area_048_km'] = gdf_wgs84.apply(\n",
        "        lambda row: haversine_distance(row['latitude'], row['longitude'], area_048_lat, area_048_lon),\n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nProximity to Area 048:\")\n",
        "    print(f\"  Min distance: {gdf_wgs84['distance_to_area_048_km'].min():.2f} km\")\n",
        "    print(f\"  Max distance: {gdf_wgs84['distance_to_area_048_km'].max():.2f} km\")\n",
        "    print(f\"  Avg distance: {gdf_wgs84['distance_to_area_048_km'].mean():.2f} km\")\n",
        "    print(f\"  Points within 200km: {(gdf_wgs84['distance_to_area_048_km'] <= 200).sum():,} ({(gdf_wgs84['distance_to_area_048_km'] <= 200).sum() / len(gdf_wgs84) * 100:.1f}%)\")\n",
        "    print(f\"\\n‚ö†Ô∏è  Note: Southern GYE is ~200 miles from Area 048.\")\n",
        "    print(f\"   This data is valuable for large sample size training.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Analyze Temporal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TEMPORAL ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Date range: 2007-03-14 00:00:00 to 2015-07-31 10:00:00\n",
            "Total days: 3061\n",
            "\n",
            "Year distribution:\n",
            "  2007: 2,881 points (3.0%)\n",
            "  2008: 9,734 points (10.3%)\n",
            "  2009: 12,680 points (13.4%)\n",
            "  2010: 13,512 points (14.3%)\n",
            "  2011: 11,167 points (11.8%)\n",
            "  2012: 15,135 points (16.0%)\n",
            "  2013: 18,983 points (20.1%)\n",
            "  2014: 9,155 points (9.7%)\n",
            "  2015: 1,344 points (1.4%)\n",
            "\n",
            "Month distribution:\n",
            "  February (2): 103 points (0.1%)\n",
            "  March (3): 3,292 points (3.5%)\n",
            "  April (4): 19,724 points (20.9%)\n",
            "  May (5): 24,432 points (25.8%)\n",
            "  June (6): 22,954 points (24.3%)\n",
            "  July (7): 24,086 points (25.5%)\n",
            "\n",
            "üìã Note: This dataset focuses on Feb-July (brucellosis risk period)\n",
            "   October data may be limited, but still valuable for general patterns.\n",
            "\n",
            "‚ö†Ô∏è  No October data (expected - dataset focuses on Feb-July)\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TEMPORAL ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Parse date column (format: M/D/YYYY H:MM)\n",
        "    try:\n",
        "        gdf_wgs84['date'] = pd.to_datetime(gdf_wgs84['Date_Time_MST'], format='%m/%d/%Y %H:%M')\n",
        "        gdf_wgs84['year'] = gdf_wgs84['date'].dt.year\n",
        "        gdf_wgs84['month'] = gdf_wgs84['date'].dt.month\n",
        "        gdf_wgs84['day_of_year'] = gdf_wgs84['date'].dt.dayofyear\n",
        "        \n",
        "        print(f\"\\nDate range: {gdf_wgs84['date'].min()} to {gdf_wgs84['date'].max()}\")\n",
        "        print(f\"Total days: {(gdf_wgs84['date'].max() - gdf_wgs84['date'].min()).days}\")\n",
        "        \n",
        "        print(f\"\\nYear distribution:\")\n",
        "        for year, count in gdf_wgs84['year'].value_counts().sort_index().items():\n",
        "            print(f\"  {int(year)}: {count:,} points ({count/len(gdf_wgs84)*100:.1f}%)\")\n",
        "        \n",
        "        print(f\"\\nMonth distribution:\")\n",
        "        for month, count in gdf_wgs84['month'].value_counts().sort_index().items():\n",
        "            month_name = pd.to_datetime(f\"2020-{month}-01\").strftime(\"%B\")\n",
        "            print(f\"  {month_name} ({month}): {count:,} points ({count/len(gdf_wgs84)*100:.1f}%)\")\n",
        "        \n",
        "        # Note: Data is Feb-July (brucellosis risk period)\n",
        "        print(f\"\\nüìã Note: This dataset focuses on Feb-July (brucellosis risk period)\")\n",
        "        print(f\"   October data may be limited, but still valuable for general patterns.\")\n",
        "        \n",
        "        # Check October data\n",
        "        october_points = gdf_wgs84[gdf_wgs84['month'] == 10]\n",
        "        if len(october_points) > 0:\n",
        "            print(f\"\\nüéØ October data: {len(october_points):,} points ({len(october_points)/len(gdf_wgs84)*100:.1f}%)\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  No October data (expected - dataset focuses on Feb-July)\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not parse dates: {e}\")\n",
        "        print(f\"   Date format: {gdf_wgs84['Date_Time_MST'].iloc[0]}\")\n",
        "        print(f\"   Try adjusting the date format string if needed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Analyze Elk Individual Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ELK INDIVIDUAL ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Total unique elk (AID): 288\n",
            "Total GPS points: 94,591\n",
            "Average points per elk: 328\n",
            "\n",
            "Points per elk:\n",
            "  Minimum: 31\n",
            "  Maximum: 954\n",
            "  Mean: 328\n",
            "  Median: 324\n",
            "\n",
            "Top 5 elk by point count:\n",
            "  Elk 88: 954 points\n",
            "  Elk 245: 765 points\n",
            "  Elk 917: 750 points\n",
            "  Elk 913: 750 points\n",
            "  Elk 679: 744 points\n",
            "\n",
            "Feedground distribution:\n",
            "  National_Elk_Refuge: 12,441 points (13.2%)\n",
            "  Gros_Ventre: 12,271 points (13.0%)\n",
            "  Jewett: 9,565 points (10.1%)\n",
            "  Muddy_Creek: 7,343 points (7.8%)\n",
            "  Fall_Creek: 6,743 points (7.1%)\n",
            "  McNeel: 6,142 points (6.5%)\n",
            "  Soda_Lake: 5,834 points (6.2%)\n",
            "  Greys_River: 4,696 points (5.0%)\n",
            "  Forest_Park: 4,173 points (4.4%)\n",
            "  South_Park: 3,533 points (3.7%)\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ELK INDIVIDUAL ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(f\"\\nTotal unique elk (AID): {gdf_wgs84['AID'].nunique()}\")\n",
        "    print(f\"Total GPS points: {len(gdf_wgs84):,}\")\n",
        "    print(f\"Average points per elk: {len(gdf_wgs84) / gdf_wgs84['AID'].nunique():.0f}\")\n",
        "    \n",
        "    points_per_elk = gdf_wgs84['AID'].value_counts()\n",
        "    print(f\"\\nPoints per elk:\")\n",
        "    print(f\"  Minimum: {points_per_elk.min():,}\")\n",
        "    print(f\"  Maximum: {points_per_elk.max():,}\")\n",
        "    print(f\"  Mean: {points_per_elk.mean():.0f}\")\n",
        "    print(f\"  Median: {points_per_elk.median():.0f}\")\n",
        "    \n",
        "    print(f\"\\nTop 5 elk by point count:\")\n",
        "    for elk_id, count in points_per_elk.head().items():\n",
        "        print(f\"  Elk {elk_id}: {count:,} points\")\n",
        "    \n",
        "    # Feedground analysis\n",
        "    print(f\"\\nFeedground distribution:\")\n",
        "    feedground_counts = gdf_wgs84['Feedground'].value_counts()\n",
        "    for feedground, count in feedground_counts.head(10).items():\n",
        "        print(f\"  {feedground}: {count:,} points ({count/len(gdf_wgs84)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Prepare Data for PathWild Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PATHWILD-READY DATASET\n",
            "============================================================\n",
            "\n",
            "Shape: (94591, 11)\n",
            "Columns: ['latitude', 'longitude', 'distance_to_area_048_km', 'elk_id', 'feedground', 'date', 'year', 'month', 'day_of_year', 'utm_easting', 'utm_northing']\n",
            "\n",
            "First few rows:\n",
            "    latitude   longitude  distance_to_area_048_km  elk_id    feedground  \\\n",
            "0  42.695323 -110.140098               320.296093      17  Bench_Corral   \n",
            "1  42.700195 -110.140016               320.440500      17  Bench_Corral   \n",
            "2  42.697538 -110.146706               320.883282      17  Bench_Corral   \n",
            "3  42.736050 -110.119038               319.937610      17  Bench_Corral   \n",
            "4  42.735406 -110.124892               320.373967      17  Bench_Corral   \n",
            "\n",
            "                 date  year  month  day_of_year  utm_easting  utm_northing  \n",
            "0 2008-03-21 04:00:00  2008      3           81  570434.7207   4727340.258  \n",
            "1 2008-03-21 08:00:00  2008      3           81  570435.9304   4727881.330  \n",
            "2 2008-03-21 12:00:00  2008      3           81  569890.9708   4727580.732  \n",
            "3 2008-03-22 04:00:00  2008      3           82  572112.5855   4731880.513  \n",
            "4 2008-03-22 08:00:00  2008      3           82  571634.1351   4731804.016  \n",
            "\n",
            "‚úì Saved to ../data/processed/southern_gye_points.csv\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    # Create PathWild-ready dataset\n",
        "    pathwild_data = pd.DataFrame({\n",
        "        'latitude': gdf_wgs84['latitude'],\n",
        "        'longitude': gdf_wgs84['longitude'],\n",
        "        'distance_to_area_048_km': gdf_wgs84['distance_to_area_048_km'],\n",
        "        'elk_id': gdf_wgs84['AID'],\n",
        "        'feedground': gdf_wgs84['Feedground']\n",
        "    })\n",
        "    \n",
        "    # Add temporal info if available\n",
        "    if 'date' in gdf_wgs84.columns:\n",
        "        pathwild_data['date'] = gdf_wgs84['date']\n",
        "        pathwild_data['year'] = gdf_wgs84['year']\n",
        "        pathwild_data['month'] = gdf_wgs84['month']\n",
        "        pathwild_data['day_of_year'] = gdf_wgs84['day_of_year']\n",
        "    \n",
        "    # Add original UTM coordinates (useful for reference)\n",
        "    pathwild_data['utm_easting'] = gdf_wgs84['Easting']\n",
        "    pathwild_data['utm_northing'] = gdf_wgs84['Northing']\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"PATHWILD-READY DATASET\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nShape: {pathwild_data.shape}\")\n",
        "    print(f\"Columns: {list(pathwild_data.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(pathwild_data.head())\n",
        "    \n",
        "    # Save to CSV\n",
        "    output_file = Path(\"../data/processed/southern_gye_points.csv\")\n",
        "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    pathwild_data.to_csv(output_file, index=False)\n",
        "    print(f\"\\n‚úì Saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SOUTHERN GYE DATASET SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total GPS points: 94,591\n",
            "Unique elk: 288\n",
            "Unique feedgrounds: 20\n",
            "\n",
            "Geographic coverage:\n",
            "  Latitude: 42.5352¬∞ to 44.2879¬∞\n",
            "  Longitude: -111.0527¬∞ to -109.1663¬∞\n",
            "\n",
            "Proximity to Area 048:\n",
            "  Average distance: 353.23 km\n",
            "\n",
            "Temporal coverage:\n",
            "  Years: [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n",
            "  Months: [2, 3, 4, 5, 6, 7]\n",
            "\n",
            "üìã Key Insights:\n",
            "  ‚úì LARGE sample size (94,591 points from 288 elk)\n",
            "  ‚úì Excellent for statistical robustness\n",
            "  ‚úì Diverse conditions across 20 feedgrounds\n",
            "  ‚ö†Ô∏è  Geographic distance from Area 048 (~200 miles)\n",
            "  ‚ö†Ô∏è  Data focuses on Feb-July (brucellosis period)\n",
            "  ‚Üí Best used for large-scale training and generalization\n",
            "\n",
            "Next steps:\n",
            "  1. Combine with South Bighorn + National Elk Refuge data\n",
            "  2. Use for large sample size training\n",
            "  3. Integrate with DataContextBuilder to add environmental features\n",
            "  4. Create training dataset with positive examples (GPS points)\n",
            "  5. Generate negative examples (random points)\n",
            "  6. Train XGBoost model with weighted combination of all datasets\n"
          ]
        }
      ],
      "source": [
        "if 'gdf_wgs84' in locals() and gdf_wgs84 is not None:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SOUTHERN GYE DATASET SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTotal GPS points: {len(gdf_wgs84):,}\")\n",
        "    print(f\"Unique elk: {gdf_wgs84['AID'].nunique()}\")\n",
        "    print(f\"Unique feedgrounds: {gdf_wgs84['Feedground'].nunique()}\")\n",
        "    print(f\"\\nGeographic coverage:\")\n",
        "    print(f\"  Latitude: {gdf_wgs84['latitude'].min():.4f}¬∞ to {gdf_wgs84['latitude'].max():.4f}¬∞\")\n",
        "    print(f\"  Longitude: {gdf_wgs84['longitude'].min():.4f}¬∞ to {gdf_wgs84['longitude'].max():.4f}¬∞\")\n",
        "    print(f\"\\nProximity to Area 048:\")\n",
        "    print(f\"  Average distance: {gdf_wgs84['distance_to_area_048_km'].mean():.2f} km\")\n",
        "    \n",
        "    if 'year' in gdf_wgs84.columns:\n",
        "        print(f\"\\nTemporal coverage:\")\n",
        "        print(f\"  Years: {sorted(gdf_wgs84['year'].unique())}\")\n",
        "        print(f\"  Months: {sorted(gdf_wgs84['month'].unique())}\")\n",
        "    \n",
        "    print(f\"\\nüìã Key Insights:\")\n",
        "    print(f\"  ‚úì LARGE sample size ({len(gdf_wgs84):,} points from {gdf_wgs84['AID'].nunique()} elk)\")\n",
        "    print(f\"  ‚úì Excellent for statistical robustness\")\n",
        "    print(f\"  ‚úì Diverse conditions across {gdf_wgs84['Feedground'].nunique()} feedgrounds\")\n",
        "    print(f\"  ‚ö†Ô∏è  Geographic distance from Area 048 (~200 miles)\")\n",
        "    print(f\"  ‚ö†Ô∏è  Data focuses on Feb-July (brucellosis period)\")\n",
        "    print(f\"  ‚Üí Best used for large-scale training and generalization\")\n",
        "    \n",
        "    print(f\"\\nNext steps:\")\n",
        "    print(\"  1. Combine with South Bighorn + National Elk Refuge data\")\n",
        "    print(\"  2. Use for large sample size training\")\n",
        "    print(\"  3. Integrate with DataContextBuilder to add environmental features\")\n",
        "    print(\"  4. Create training dataset with positive examples (GPS points)\")\n",
        "    print(\"  5. Generate negative examples (random points)\")\n",
        "    print(\"  6. Train XGBoost model with weighted combination of all datasets\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pathwild",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
